{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d75cf7",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e6fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_parameter_percentage = 1.0\n",
    "model_parameter_name = 'cbm'\n",
    "gpu_id = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a427b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6783e21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation/mnist/notebooks', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python38.zip', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8/lib-dynload', '', '/users-1/eleonora/.local/lib/python3.8/site-packages', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8/site-packages', '/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation/mnist', '/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation', '/users-1/eleonora/reasoning-shortcuts/IXShort']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import setproctitle, socket, uuid\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from argparse import Namespace\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "sys.path.append(os.path.abspath(\"..\"))       # for 'protonet_mnist_add_utils' folder\n",
    "sys.path.append(os.path.abspath(\"../..\"))    # for 'data' folder\n",
    "sys.path.append(os.path.abspath(\"../../..\")) # for 'models' and 'datasets' folders\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386f1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_model\n",
    "from models.mnistdpl import MnistDPL\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "from utils import fprint\n",
    "from utils.checkpoint import save_model\n",
    "from utils.status import progress_bar\n",
    "from utils.dpl_loss import ADDMNIST_DPL\n",
    "from utils.metrics import evaluate_metrics\n",
    "from utils.train import convert_to_categories, compute_coverage\n",
    "\n",
    "from backbones.addmnist_protonet import PrototypicalLoss\n",
    "\n",
    "from protonet_mnist_add_modules.utility_modules import sanity_checker\n",
    "from protonet_mnist_add_modules.data_modules import my_datasets\n",
    "from protonet_mnist_add_modules.data_modules.proto_data_creation import (\n",
    "    choose_initial_prototypes, \n",
    "    get_augmented_support_query_set, \n",
    "    get_augmented_support_query_loader\n",
    ")\n",
    "from protonet_mnist_add_modules.utility_modules.proto_utils import (\n",
    "    init_dataloader, \n",
    "    get_random_classes\n",
    ")\n",
    "from protonet_mnist_add_modules.data_modules.prototypical_batch_sampler import PrototypicalBatchSampler\n",
    "from protonet_mnist_add_modules.utility_modules.plotting import plot_episodic_dataloader\n",
    "\n",
    "#from protonet_mnist_math_modules.arguments import args_dpl, args_cbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfbd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_cbm = Namespace(\n",
    "    and_op='Godel',\n",
    "    backbone='conceptizer', \n",
    "    batch_size=64, # & ok          \n",
    "    beta=0.99,                      \n",
    "    boia_model='ce', \n",
    "    boia_ood_knowledge=False, \n",
    "    c_sup=0.05, \n",
    "    c_sup_ltn=0, \n",
    "    checkin=None, \n",
    "    checkout=False, \n",
    "    count=30, \n",
    "    dataset='mnmath',     \n",
    "    entity='', \n",
    "    entropy=False, \n",
    "    exp_decay=0.9,                  \n",
    "    gamma=1e-3,                      \n",
    "    imp_op='Prod',\n",
    "    joint=False, \n",
    "    lr=0.001,  # & ok                     \n",
    "    model='promnmathcbm',   # ^ 'mnmathcbm' for CBM model and 'promnmathdpl' for DPL + PNet          \n",
    "    n_epochs=40,\n",
    "    non_verbose=False, \n",
    "    notes=None, \n",
    "    or_op='Prod',           \n",
    "    p=6,                    \n",
    "    posthoc=False, \n",
    "    preprocess=False, \n",
    "    proj_name='', \n",
    "    project='Reasoning-Shortcuts', \n",
    "    seeds=[], \n",
    "    splitted=False, \n",
    "    task='mnmath', \n",
    "    tuning=False, \n",
    "    use_ood=False, \n",
    "    val_metric='accuracy', \n",
    "    validate=False, \n",
    "    w_c=1, \n",
    "    w_h=0,                       \n",
    "    w_rec=1, \n",
    "    w_sl=10,\n",
    "    wandb=None, \n",
    "    warmup_steps=0, \n",
    "    weight_decay=0.0001,  # & ok          \n",
    "    which_c=[9],\n",
    "    device=torch.device(\"cuda\"),\n",
    "    \n",
    "    seed = 1415,        # 1415, 1617, 1819, || 2021, 2223.\n",
    "    patience = 15,\n",
    "    prototypes=True,\n",
    "    prototypical_dataset='addmnist', # ^ dataset with complete digits to create support and query set\n",
    "    prototypical_batch_size=32,\n",
    "    n_support=75,\n",
    "    embedding_dim=64,\n",
    "    debug=False,\n",
    "    proto_lr=0.001,\n",
    "    proto_epochs=10,\n",
    "    hide=[],\n",
    "\n",
    "    num_support = 5,                         # ✅ Episodic training\n",
    "    num_query = 5,                           # ✅ Episodic training\n",
    "    num_samples = 10,                        # ✅ Episodic training (num_support + num_query\n",
    "    classes_per_it = 5,                      # ✅ Episodic training\n",
    "    iterations = 100,                        # ✅ Episodic training\n",
    "\n",
    "    no_interaction = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13a8cb",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96fecc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save paths: ../notebook-outputs/mnmath/my_models/cbm/episodic-proto-net-pipeline-1.0\n"
     ]
    }
   ],
   "source": [
    "if model_parameter_name == 'dpl':\n",
    "    args = args_dpl\n",
    "else:\n",
    "    args = args_cbm\n",
    "\n",
    "# logging\n",
    "args.conf_jobnum = str(uuid.uuid4())\n",
    "args.conf_timestamp = str(datetime.datetime.now())\n",
    "args.conf_host = socket.gethostname()\n",
    "\n",
    "# set job name\n",
    "setproctitle.setproctitle(\n",
    "    \"{}_{}_{}\".format(\n",
    "        args.model,\n",
    "        args.buffer_size if \"buffer_size\" in args else 0,\n",
    "        args.dataset,\n",
    "    )\n",
    ")\n",
    "\n",
    "# saving\n",
    "save_folder = \"mnmath\" \n",
    "save_model_name = model_parameter_name\n",
    "\n",
    "save_path = os.path.join(\"..\",\n",
    "    \"notebook-outputs\", \n",
    "    save_folder, \n",
    "    \"my_models\", \n",
    "    save_model_name,\n",
    "    f\"episodic-proto-net-pipeline-{uns_parameter_percentage}\"\n",
    ")\n",
    "print(f\"Save paths: {str(save_path)}\")\n",
    "\n",
    "if args.model in ['mnmathdpl', 'mnmathcbm'] or not args.prototypes:\n",
    "    raise ValueError(\"This experiment is not meant for baseline models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b1ef8",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22adc700",
   "metadata": {},
   "source": [
    "Plots the first *n* images from a batch, with their labels and concept annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d85f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, concepts, n=3):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        images (torch.Tensor): Shape [B, 1, 28, 224] - batch of concatenated MNIST digits.\n",
    "        labels (torch.Tensor): Shape [B, 2] - two binary labels per image.\n",
    "        concepts (torch.Tensor): Shape [B, 2, 4] - concept annotations per digit.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, n, figsize=(12, 5))\n",
    "\n",
    "    for i in range(n):\n",
    "        img = images[i].squeeze(0)  # Shape [28, 224]\n",
    "        lbl = labels[i].tolist()\n",
    "        cpt = concepts[i].tolist()\n",
    "\n",
    "        axs[i].imshow(img, cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "        \n",
    "        axs[i].set_title(f\"Labels: {lbl}\", fontsize=10)\n",
    "        axs[i].text(0.5, -0.1,\n",
    "                    f\"Concepts: {cpt}\",\n",
    "                    fontsize=8,\n",
    "                    ha='center',\n",
    "                    va='top',\n",
    "                    transform=axs[i].transAxes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72096f",
   "metadata": {},
   "source": [
    "Returns the support and query loaders for the prototypical network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be08949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_support_query_sets_and_loaders(args):\n",
    "    args_protonet = Namespace(\n",
    "        dataset=args.prototypical_dataset,     \n",
    "        batch_size=args.prototypical_batch_size,\n",
    "        preprocess=0,\n",
    "        c_sup=1,    # ^ supervision loaded to simulate direct annotation for prototypes\n",
    "        which_c=[-1],\n",
    "        model=args.model,        \n",
    "        task=args.task,    \n",
    "    )\n",
    "    addmnist_dataset = get_dataset(args_protonet)\n",
    "    addmnist_train_loader, _ , _ = addmnist_dataset.get_data_loaders()\n",
    "\n",
    "    if ( (not os.path.exists('data/prototypes/proto_loader_dataset.pth')) or args.debug ):\n",
    "        print(\"Creating initial prototypes...\")\n",
    "        choose_initial_prototypes(addmnist_train_loader, debug=args.debug)\n",
    "\n",
    "    tr_dataloader = init_dataloader()\n",
    "    support_images_aug, support_labels_aug, query_images_aug, query_labels_aug, no_aug = get_augmented_support_query_set(\n",
    "        tr_dataloader, debug=args.debug)\n",
    "    support_loader, query_loader = get_augmented_support_query_loader(\n",
    "        support_images_aug, \n",
    "        support_labels_aug, \n",
    "        query_images_aug, \n",
    "        query_labels_aug,\n",
    "        query_batch_size=32,\n",
    "        debug=args.debug\n",
    "    )\n",
    "\n",
    "    return support_loader, support_images_aug, support_labels_aug, query_loader, no_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e8657",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778528f",
   "metadata": {},
   "source": [
    "## Load Annotated Prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828b38c",
   "metadata": {},
   "source": [
    "run all things about protonets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7d76d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['mnmath', 'xor', 'clipboia', 'shortmnist', 'restrictedmnist', 'minikandinsky', 'presddoia', 'prekandinsky', 'sddoia', 'clipkandinsky', 'addmnist', 'clipshortmnist', 'boia_original', 'boia_original_embedded', 'clipsddoia', 'boia', 'kandinsky', 'halfmnist']\n",
      "Loading train data\n",
      "Loading val data\n",
      "Loading test data\n",
      "Number of rotations:  400\n",
      "Number of translations:  1440\n",
      "Number of scalings:  100\n",
      "Number of elastic transformations:  250\n",
      "Number of noising transformations:  40\n",
      "Number of distinct labels: 10\n",
      "Classes in dataset: [0 1 2 3 4 5 6 7 8 9]\n",
      "Batch images shape: torch.Size([50, 1, 28, 28])\n",
      "Batch labels: [0, 3, 5, 0, 0, 9, 9, 3, 0, 3, 0, 9, 5, 6, 9, 3, 3, 9, 6, 6, 6, 9, 0, 5, 0, 0, 9, 0, 3, 6, 6, 6, 3, 3, 5, 5, 0, 3, 5, 5, 9, 5, 6, 6, 3, 9, 9, 6, 5, 5]\n",
      "Label distribution in batch: Counter({0: 10, 3: 10, 5: 10, 9: 10, 6: 10})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "support_loader, support_images_aug, support_labels_aug, query_loader, _ = create_support_query_sets_and_loaders(args)\n",
    "mnist_dataset = my_datasets.MNISTAugDataset(support_images_aug, support_labels_aug, hide_labels=args.hide)\n",
    "sanity_checker.assert_my_labels(args, support_labels_aug, mnist_dataset)\n",
    "proto_labels = mnist_dataset.labels.squeeze().numpy()\n",
    "episodic_dataloader = DataLoader(my_datasets.EmptyDataset(), batch_size=1)\n",
    "if args.classes_per_it > 0:\n",
    "    sampler = PrototypicalBatchSampler(proto_labels, args.classes_per_it, args.num_samples, args.iterations)\n",
    "    episodic_dataloader = DataLoader(mnist_dataset, batch_sampler=sampler)\n",
    "plot_episodic_dataloader(episodic_dataloader, args.num_support, args.num_query, args.classes_per_it, args)\n",
    "\n",
    "assert torch.equal(torch.sort(torch.unique(torch.tensor(proto_labels)))[0], torch.arange(0, 10)),\\\n",
    "    \"proto_labels must contain all values from 0 to 9\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c03d7",
   "metadata": {},
   "source": [
    "## Unsupervised Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcad9f",
   "metadata": {},
   "source": [
    "load the unsupervised training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157cc277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['mnmath', 'xor', 'clipboia', 'shortmnist', 'restrictedmnist', 'minikandinsky', 'presddoia', 'prekandinsky', 'sddoia', 'clipkandinsky', 'addmnist', 'clipshortmnist', 'boia_original', 'boia_original_embedded', 'clipsddoia', 'boia', 'kandinsky', 'halfmnist']\n",
      "Loaded datasets in 0.5619585514068604 s.\n",
      "Len loaders: \n",
      " train: 1000 \n",
      " val: 200\n",
      " len test: 300\n",
      "## Statistics ##\n",
      "Train samples 1000\n",
      "Validation samples 200\n",
      "Test samples 300\n",
      "Test OOD samples 300\n"
     ]
    }
   ],
   "source": [
    "mnmath_dataset = get_dataset(args)\n",
    "mnmath_train_loader, mnmath_val_loader, mnmath_test_loader, mnmath_ood_loader = mnmath_dataset.get_data_loaders()\n",
    "mnmath_dataset.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12d14e",
   "metadata": {},
   "source": [
    "### Unsupervised Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa9bca",
   "metadata": {},
   "source": [
    "*See some statistics about the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f132a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1000\n",
      "First label == 1: 437 (43.70%)\n",
      "Second label == 1: 125 (12.50%)\n",
      "Both labels == 1: 63 (6.30%)\n"
     ]
    }
   ],
   "source": [
    "first_label_1 = 0\n",
    "second_label_1 = 0\n",
    "both_labels_1 = 0\n",
    "total = 0\n",
    "\n",
    "for data in mnmath_train_loader:\n",
    "    _, labels, _ = data  # labels shape: [batch_size, 2]\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    first_label_1 += (labels[:, 0] == 1).sum().item()\n",
    "    second_label_1 += (labels[:, 1] == 1).sum().item()\n",
    "    both_labels_1 += ((labels[:, 0] == 1) & (labels[:, 1] == 1)).sum().item()\n",
    "\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"First label == 1: {first_label_1} ({100 * first_label_1 / total:.2f}%)\")\n",
    "print(f\"Second label == 1: {second_label_1} ({100 * second_label_1 / total:.2f}%)\")\n",
    "print(f\"Both labels == 1: {both_labels_1} ({100 * both_labels_1 / total:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad429f",
   "metadata": {},
   "source": [
    "*Plotting some examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c73713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in mnmath_train_loader:\n",
    "    images, labels, concepts = data  # shapes: [32, 1, 28, 224], [32, 2], [32, 2, 4]\n",
    "    \n",
    "    # Filter indices where either label[0] or label[1] is 1\n",
    "    mask = (labels[:, 0] == 1) | (labels[:, 1] == 1)\n",
    "    indices = torch.nonzero(mask).squeeze()\n",
    "\n",
    "    if len(indices) >= 3:\n",
    "        selected_images = images[indices[:3]]\n",
    "        selected_labels = labels[indices[:3]]\n",
    "        selected_concepts = concepts[indices[:3]]\n",
    "\n",
    "        plot_images(selected_images, selected_labels, selected_concepts)\n",
    "    else:\n",
    "        print(\"Not enough samples with at least one positive label in this batch.\")\n",
    "    \n",
    "    break  # only process one batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cf678",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6797b615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BACKBONE-INFO] Using Prototypical Networks as backbone\n",
      "Available models: ['promnistltn', 'promnmathcbm', 'sddoiann', 'kandnn', 'sddoiadpl', 'sddoialtn', 'presddoiadpl', 'boiann', 'mnistclip', 'prokanddpl', 'promnistdpl', 'xornn', 'mnistnn', 'mnistslrec', 'kandpreprocess', 'kandsl', 'kandsloneembedding', 'prokandltn', 'kandcbm', 'prokandsl', 'boiacbm', 'kanddpl', 'kandltn', 'xorcbm', 'sddoiaclip', 'xordpl', 'promnmathdpl', 'sddoiacbm', 'mnistltnrec', 'mnmathcbm', 'mnmathdpl', 'kandclip', 'minikanddpl', 'mnistdpl', 'mnistltn', 'boiadpl', 'boialtn', 'prokandsloneembedding', 'mnistpcbmdpl', 'mnistcbm', 'probddoiadpl', 'mnistpcbmsl', 'mnistpcbmltn', 'mnistsl', 'mnistdplrec', 'cvae', 'cext', 'mnmathnn', 'promnistsl']\n",
      "Using Dataset:  <datasets.mnmath.MNMATH object at 0x7f1864f41ac0>\n",
      "Using backbone:  ProtoNet(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Using Model:  ProMNMATHCBM(\n",
      "  (encoder): ProtoNet(\n",
      "    (encoder): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=80, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=5, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=5, out_features=2, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Using Loss:  MNMATH_DPL()\n"
     ]
    }
   ],
   "source": [
    "n_images, c_split = mnmath_dataset.get_split()\n",
    "encoder, decoder = mnmath_dataset.get_backbone()\n",
    "model = get_model(args, encoder, decoder, n_images, c_split)\n",
    "loss = model.get_loss(args)\n",
    "\n",
    "print(\"Using Dataset: \", mnmath_dataset)\n",
    "print(\"Using backbone: \", encoder)\n",
    "print(\"Using Model: \", model)\n",
    "print(\"Using Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d834b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.encoder.0.0.weight',\n",
       "              tensor([[[[-5.2731e-02, -1.5567e-01,  1.7355e-01],\n",
       "                        [ 2.7088e-01,  1.5157e-01,  4.8427e-04],\n",
       "                        [ 2.9357e-01, -3.7351e-02, -3.8168e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.0817e-03,  1.2914e-01, -7.2741e-02],\n",
       "                        [ 3.3290e-01, -3.7903e-02,  1.1249e-01],\n",
       "                        [-2.4634e-02, -2.0828e-01, -1.0900e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2215e-01, -1.0751e-01,  3.0119e-01],\n",
       "                        [ 1.8278e-01,  2.3675e-01,  1.6090e-01],\n",
       "                        [-1.6056e-01, -1.8641e-01,  2.7963e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.8933e-02,  6.0986e-02,  9.2315e-03],\n",
       "                        [ 1.9049e-01, -5.0984e-02, -1.0693e-01],\n",
       "                        [-3.0425e-01,  1.4584e-01,  4.3102e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8062e-01,  2.8751e-01,  2.9447e-01],\n",
       "                        [ 1.2761e-01, -2.5433e-01,  1.0669e-01],\n",
       "                        [ 2.2405e-01,  1.7985e-01, -1.6285e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0445e-02, -1.4506e-01,  2.2818e-01],\n",
       "                        [ 2.8046e-01, -8.4049e-02, -3.8761e-02],\n",
       "                        [ 1.2702e-01,  4.4791e-02,  6.5126e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1336e-01, -3.0248e-01, -9.1580e-02],\n",
       "                        [ 1.6090e-01, -2.9439e-01,  1.7818e-01],\n",
       "                        [ 8.1037e-02,  2.0119e-01, -2.6552e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.8508e-02,  7.6704e-02, -2.4760e-01],\n",
       "                        [ 2.9479e-01, -2.3247e-01, -1.9811e-01],\n",
       "                        [ 1.7185e-01, -8.5434e-02, -3.3031e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9644e-01, -2.2628e-01, -1.0332e-01],\n",
       "                        [-8.4210e-02, -2.0160e-01,  2.1153e-02],\n",
       "                        [ 1.5372e-01, -2.5081e-01, -2.7332e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5774e-02,  3.2903e-01,  3.7690e-02],\n",
       "                        [ 2.4772e-01, -3.2334e-01, -3.8952e-02],\n",
       "                        [ 1.2881e-01,  2.3819e-01, -1.3406e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8433e-01, -1.1691e-01,  2.5694e-01],\n",
       "                        [ 1.2480e-01, -3.5121e-02, -1.0953e-01],\n",
       "                        [ 2.9015e-01, -5.2485e-03, -3.2580e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.4453e-02, -2.7146e-02,  1.6684e-01],\n",
       "                        [ 1.4630e-01,  2.1342e-01,  2.4687e-01],\n",
       "                        [ 1.0208e-02, -1.9614e-01, -2.4934e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0493e-01,  2.4841e-01,  1.1880e-02],\n",
       "                        [ 1.9587e-01,  1.8487e-01, -1.5336e-01],\n",
       "                        [-3.0654e-01, -1.4868e-01,  1.0596e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9837e-01, -9.2798e-02,  2.6608e-01],\n",
       "                        [ 1.4905e-01,  1.7973e-01,  2.9554e-01],\n",
       "                        [ 3.0739e-01,  1.2324e-01, -1.1169e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5081e-01, -4.4858e-02,  2.3016e-02],\n",
       "                        [ 3.2847e-01,  2.4374e-01, -2.6313e-01],\n",
       "                        [ 1.7290e-01,  2.3713e-01,  1.5123e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0652e-01, -3.2301e-01, -2.3742e-01],\n",
       "                        [ 3.1668e-01, -2.6639e-01, -2.6021e-01],\n",
       "                        [ 1.1722e-01, -1.8777e-01,  2.6737e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8469e-02,  1.2798e-01, -1.9686e-01],\n",
       "                        [-1.6222e-01,  2.0427e-02, -4.7536e-02],\n",
       "                        [ 2.0121e-01, -1.0952e-01,  1.0494e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2621e-01,  1.4835e-01,  5.1162e-02],\n",
       "                        [-3.2163e-01, -2.9344e-01, -2.1705e-01],\n",
       "                        [-2.2928e-01,  1.6898e-01,  1.1703e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9412e-01,  1.6288e-01, -1.0538e-01],\n",
       "                        [ 3.2768e-01, -3.0958e-01, -2.4012e-01],\n",
       "                        [ 1.0549e-01,  1.5229e-01, -1.2922e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.5922e-02, -9.3234e-02,  3.2737e-01],\n",
       "                        [ 2.7975e-01, -7.1972e-02, -1.1522e-01],\n",
       "                        [ 3.1459e-01,  1.4815e-01, -9.8557e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.6431e-02,  5.4050e-02, -3.0086e-02],\n",
       "                        [-1.3589e-01, -2.7817e-01, -2.7802e-01],\n",
       "                        [-9.2912e-02,  2.1756e-01, -2.9645e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9967e-01, -7.1739e-03, -8.1798e-03],\n",
       "                        [ 3.2785e-01,  6.1232e-02, -1.5900e-01],\n",
       "                        [ 3.2676e-01,  1.5709e-01, -2.1209e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6858e-03,  2.9951e-01,  1.4575e-02],\n",
       "                        [-2.9719e-01, -3.2902e-01,  2.0572e-02],\n",
       "                        [-3.2462e-01,  1.7142e-01,  2.5525e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7492e-01, -1.4882e-01,  1.5152e-04],\n",
       "                        [ 1.8454e-01,  2.7983e-01, -5.1585e-02],\n",
       "                        [-1.0562e-01, -6.7852e-02,  4.0787e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8189e-01, -2.8711e-01, -2.1486e-01],\n",
       "                        [-1.7004e-01, -2.0010e-01, -1.6933e-01],\n",
       "                        [-3.1841e-01,  3.0736e-01,  5.9550e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.8399e-02, -3.1767e-01,  3.2703e-02],\n",
       "                        [ 2.7142e-01,  2.1313e-01, -4.3906e-02],\n",
       "                        [-2.8265e-01,  2.6687e-01,  2.1445e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1975e-01, -1.0309e-01, -1.2271e-01],\n",
       "                        [-1.5443e-01, -6.5208e-02, -7.7937e-02],\n",
       "                        [-1.6578e-01,  2.6000e-01,  2.7980e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2923e-02,  1.5790e-01, -1.5228e-02],\n",
       "                        [-2.6523e-01, -1.3418e-01,  2.3023e-02],\n",
       "                        [ 2.4253e-02,  2.2196e-01, -1.4323e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5127e-01,  2.0717e-01, -2.0861e-01],\n",
       "                        [-3.2284e-01,  2.6227e-01, -7.4394e-02],\n",
       "                        [-1.1847e-01, -6.6497e-02, -2.5367e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5799e-01, -1.1285e-01, -2.4565e-01],\n",
       "                        [-2.3910e-01, -6.1417e-02, -1.9469e-02],\n",
       "                        [-9.9489e-02, -1.5679e-02,  1.9603e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4013e-01,  3.1002e-01, -1.0151e-01],\n",
       "                        [-1.2207e-01, -2.8635e-01,  5.4596e-03],\n",
       "                        [-2.2660e-01, -2.9376e-01, -3.1841e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7002e-02,  1.0603e-01,  1.1902e-01],\n",
       "                        [ 2.3716e-01, -6.6741e-03, -2.9971e-01],\n",
       "                        [ 2.0181e-01,  3.3708e-02, -2.8912e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2711e-01, -2.3731e-01, -7.8398e-02],\n",
       "                        [-2.1335e-01,  9.9019e-02, -1.1165e-01],\n",
       "                        [ 7.7227e-03, -1.5232e-01, -2.2436e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3178e-01,  2.7153e-01, -2.6314e-01],\n",
       "                        [ 2.8759e-01, -2.2165e-01, -2.2013e-01],\n",
       "                        [-3.1867e-01, -6.2753e-02, -6.4640e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1554e-02,  2.4922e-02,  3.2534e-01],\n",
       "                        [ 1.3473e-01, -1.9333e-02, -2.5682e-01],\n",
       "                        [-3.7545e-02,  1.1598e-01,  2.8373e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.0929e-02,  5.5940e-02,  2.9987e-01],\n",
       "                        [ 2.6088e-01, -6.0045e-02,  5.2426e-02],\n",
       "                        [ 1.6223e-01,  2.9817e-01,  1.0359e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1291e-01,  3.2213e-01, -2.8065e-01],\n",
       "                        [-9.7913e-02, -1.3695e-01, -1.9989e-02],\n",
       "                        [-8.4086e-02,  1.3432e-01,  1.7792e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0824e-01,  1.1929e-01, -2.3061e-01],\n",
       "                        [-1.2174e-01, -6.6598e-02, -3.4201e-02],\n",
       "                        [ 5.0759e-02, -2.2918e-01, -2.2992e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2891e-01,  3.2753e-01, -3.5371e-02],\n",
       "                        [ 1.3178e-01,  8.4478e-02,  8.8452e-02],\n",
       "                        [ 2.0923e-01,  1.8355e-01, -2.1155e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0982e-01, -2.1260e-01,  2.1366e-01],\n",
       "                        [-1.0049e-03,  1.3648e-01, -2.4087e-01],\n",
       "                        [-1.0839e-01,  4.4075e-02, -1.2705e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0774e-01, -4.8859e-02,  1.5488e-01],\n",
       "                        [ 1.5908e-01,  7.0691e-02,  7.4188e-02],\n",
       "                        [ 3.9139e-02, -2.0043e-01,  4.2204e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1147e-01,  2.0873e-01, -2.1443e-01],\n",
       "                        [-1.8193e-01, -4.5158e-02, -7.0953e-02],\n",
       "                        [-3.1151e-01, -5.2947e-02, -2.1703e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9558e-01, -2.3218e-02, -2.3922e-01],\n",
       "                        [ 2.6318e-01, -2.9706e-01,  2.6565e-01],\n",
       "                        [ 9.2665e-02,  3.2006e-02, -2.4810e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.2672e-02,  2.4709e-01,  1.4131e-01],\n",
       "                        [ 1.8657e-01, -1.1300e-01,  1.8498e-01],\n",
       "                        [ 6.1973e-02,  1.1584e-01, -2.4850e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7792e-01,  2.2123e-01, -2.7725e-01],\n",
       "                        [ 1.4817e-01,  2.1916e-01, -1.9031e-01],\n",
       "                        [-1.9959e-01,  1.3454e-01, -2.0507e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5208e-01, -2.1419e-01,  1.1515e-01],\n",
       "                        [-2.7596e-02, -3.3881e-02,  2.5805e-02],\n",
       "                        [ 7.6243e-02,  1.7860e-01,  2.1567e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2148e-01,  1.0482e-01, -1.7515e-01],\n",
       "                        [-6.6741e-03,  2.7690e-01,  1.3974e-01],\n",
       "                        [-2.1691e-02,  1.1835e-01,  5.9592e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0436e-01,  1.4838e-02,  2.6361e-01],\n",
       "                        [-1.1694e-01, -2.1946e-01,  2.4981e-01],\n",
       "                        [-3.2178e-01, -1.4360e-01, -1.2415e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.6480e-02,  8.6230e-02,  2.4330e-01],\n",
       "                        [ 2.6763e-01, -1.5673e-01, -2.8196e-01],\n",
       "                        [-1.7137e-01, -2.2189e-01, -1.3127e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.4732e-03,  1.4508e-01, -3.1195e-01],\n",
       "                        [ 4.6013e-02,  3.1055e-01, -9.1913e-02],\n",
       "                        [ 4.9123e-02,  2.5925e-01, -2.0739e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9072e-02, -3.0385e-02,  1.3681e-01],\n",
       "                        [ 3.1083e-01,  8.0079e-03,  4.7448e-02],\n",
       "                        [ 2.5415e-01, -3.2342e-01,  1.5746e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2177e-01, -4.5737e-02, -3.0229e-01],\n",
       "                        [-3.2398e-01,  6.5421e-02,  2.9390e-01],\n",
       "                        [ 4.0667e-02,  2.9284e-01,  1.9328e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1388e-02, -2.4622e-01,  2.3377e-01],\n",
       "                        [-2.9815e-01,  3.1952e-01, -3.2429e-01],\n",
       "                        [-2.3508e-01,  1.5417e-01, -1.3602e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2317e-01,  3.0007e-01, -9.4859e-02],\n",
       "                        [ 1.7377e-01,  1.9635e-01,  3.2491e-01],\n",
       "                        [ 2.0958e-02,  2.3746e-02, -2.1485e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7418e-03, -2.7637e-01,  1.6782e-02],\n",
       "                        [ 2.2238e-01,  2.0468e-01, -2.3817e-01],\n",
       "                        [ 1.9358e-01, -1.7439e-01,  5.1818e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4269e-01,  1.9875e-01, -1.1994e-02],\n",
       "                        [ 1.3393e-01,  1.7776e-01, -4.4149e-02],\n",
       "                        [ 2.6898e-01, -1.7903e-01,  5.2430e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4567e-01,  3.1487e-01, -6.8221e-02],\n",
       "                        [-3.0789e-01, -1.1736e-01,  1.8044e-01],\n",
       "                        [-2.3107e-01, -1.5493e-01, -3.1842e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5454e-01,  2.8594e-02, -2.9357e-01],\n",
       "                        [ 4.0310e-02, -1.7715e-01, -1.7979e-01],\n",
       "                        [-1.5125e-01, -3.0636e-01,  1.4500e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4260e-01,  1.1536e-01, -2.3808e-01],\n",
       "                        [-8.3452e-02, -2.5757e-01, -3.1500e-01],\n",
       "                        [-1.6182e-01, -1.4299e-01, -9.8900e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6001e-01, -7.1765e-02,  2.2829e-01],\n",
       "                        [ 8.6042e-03, -4.1263e-02, -3.1491e-01],\n",
       "                        [-2.3453e-01,  1.8993e-01, -2.4942e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1382e-01,  2.4622e-01,  1.7471e-01],\n",
       "                        [-9.0817e-02,  1.4255e-01,  3.2037e-01],\n",
       "                        [-2.4483e-01, -8.9241e-02, -1.8411e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8722e-01, -1.4815e-01,  4.2527e-03],\n",
       "                        [-5.9844e-02,  3.1548e-01,  7.6305e-03],\n",
       "                        [ 5.2692e-02, -2.2568e-01,  2.9046e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2800e-01, -1.9564e-01,  6.7628e-02],\n",
       "                        [ 2.2492e-01, -4.3303e-02,  2.8748e-01],\n",
       "                        [ 5.7995e-03, -3.3287e-02, -1.8963e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8196e-01,  2.4310e-01, -4.3129e-02],\n",
       "                        [ 1.6874e-01, -8.3469e-02, -8.8164e-02],\n",
       "                        [-3.4489e-02,  2.7490e-01, -2.7779e-02]]]])),\n",
       "             ('encoder.encoder.0.0.bias',\n",
       "              tensor([-2.2111e-01, -2.9388e-01, -1.0869e-01,  1.6034e-01, -1.3216e-01,\n",
       "                      -1.5994e-01, -3.1417e-01, -4.2972e-02,  2.4931e-01,  1.2760e-01,\n",
       "                      -2.2052e-01,  3.2509e-02, -5.1333e-02,  6.2489e-02, -1.1488e-01,\n",
       "                       1.2681e-01,  7.0143e-02, -7.4578e-02, -2.7325e-01,  2.7767e-01,\n",
       "                       2.8875e-01,  2.9322e-01, -2.0824e-01,  2.2940e-01, -1.8379e-01,\n",
       "                       1.5599e-01,  1.8865e-01,  3.1395e-01,  2.5894e-01, -5.1939e-02,\n",
       "                       1.2668e-01, -2.0069e-01,  2.4757e-01, -2.8904e-01, -7.9971e-02,\n",
       "                      -3.2836e-01, -4.6621e-02,  1.4820e-01,  1.2616e-02,  1.2250e-01,\n",
       "                       1.7398e-01,  2.3560e-01,  2.8219e-01, -3.1738e-01, -3.0196e-01,\n",
       "                       2.4834e-01,  2.2399e-01,  2.7681e-01, -4.2632e-02, -6.0876e-05,\n",
       "                      -1.0208e-01,  3.1481e-02,  4.8820e-02, -1.4651e-01,  3.0734e-01,\n",
       "                      -3.0815e-01, -2.1618e-01,  8.5746e-02,  2.7982e-01,  1.9860e-01,\n",
       "                      -1.8383e-01, -5.3764e-02,  1.6137e-01, -8.2414e-02])),\n",
       "             ('encoder.encoder.0.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.0.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.0.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.0.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.0.1.num_batches_tracked', tensor(0)),\n",
       "             ('encoder.encoder.1.0.weight',\n",
       "              tensor([[[[-0.0293, -0.0294,  0.0375],\n",
       "                        [-0.0218, -0.0198,  0.0036],\n",
       "                        [-0.0215,  0.0283,  0.0281]],\n",
       "              \n",
       "                       [[-0.0273, -0.0330,  0.0034],\n",
       "                        [ 0.0359,  0.0080, -0.0170],\n",
       "                        [ 0.0406,  0.0320,  0.0414]],\n",
       "              \n",
       "                       [[ 0.0195,  0.0179,  0.0247],\n",
       "                        [ 0.0246,  0.0122,  0.0198],\n",
       "                        [-0.0309, -0.0041, -0.0156]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0164, -0.0279,  0.0196],\n",
       "                        [ 0.0339,  0.0181, -0.0031],\n",
       "                        [ 0.0062, -0.0094, -0.0352]],\n",
       "              \n",
       "                       [[ 0.0207,  0.0238, -0.0116],\n",
       "                        [-0.0014, -0.0151, -0.0327],\n",
       "                        [-0.0351,  0.0243, -0.0188]],\n",
       "              \n",
       "                       [[ 0.0316, -0.0153, -0.0014],\n",
       "                        [ 0.0234,  0.0295, -0.0403],\n",
       "                        [ 0.0017, -0.0151, -0.0220]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0368,  0.0259,  0.0153],\n",
       "                        [ 0.0049, -0.0199, -0.0044],\n",
       "                        [-0.0188,  0.0209,  0.0044]],\n",
       "              \n",
       "                       [[-0.0205,  0.0154, -0.0321],\n",
       "                        [ 0.0114,  0.0144, -0.0315],\n",
       "                        [-0.0257, -0.0186, -0.0129]],\n",
       "              \n",
       "                       [[ 0.0184, -0.0238,  0.0013],\n",
       "                        [ 0.0254,  0.0333, -0.0175],\n",
       "                        [-0.0145,  0.0079, -0.0197]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0407, -0.0166, -0.0022],\n",
       "                        [-0.0207,  0.0291,  0.0311],\n",
       "                        [ 0.0118,  0.0096, -0.0348]],\n",
       "              \n",
       "                       [[-0.0110,  0.0146, -0.0139],\n",
       "                        [-0.0375,  0.0400,  0.0120],\n",
       "                        [-0.0244,  0.0400, -0.0334]],\n",
       "              \n",
       "                       [[ 0.0017, -0.0046,  0.0221],\n",
       "                        [ 0.0380,  0.0244, -0.0272],\n",
       "                        [-0.0319, -0.0129, -0.0331]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0351, -0.0276,  0.0382],\n",
       "                        [ 0.0143,  0.0227, -0.0117],\n",
       "                        [ 0.0354, -0.0146,  0.0216]],\n",
       "              \n",
       "                       [[ 0.0044,  0.0241, -0.0386],\n",
       "                        [-0.0316, -0.0205, -0.0324],\n",
       "                        [ 0.0150, -0.0214, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0149, -0.0159, -0.0336],\n",
       "                        [-0.0058, -0.0154,  0.0206],\n",
       "                        [-0.0148, -0.0335, -0.0409]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0185,  0.0176, -0.0085],\n",
       "                        [-0.0236,  0.0061,  0.0127],\n",
       "                        [-0.0209, -0.0340,  0.0035]],\n",
       "              \n",
       "                       [[-0.0285,  0.0016, -0.0235],\n",
       "                        [ 0.0074,  0.0345,  0.0255],\n",
       "                        [ 0.0402, -0.0127, -0.0048]],\n",
       "              \n",
       "                       [[-0.0334, -0.0160,  0.0292],\n",
       "                        [-0.0278, -0.0388, -0.0409],\n",
       "                        [ 0.0008,  0.0309,  0.0292]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0411, -0.0007, -0.0092],\n",
       "                        [-0.0011, -0.0407,  0.0323],\n",
       "                        [-0.0333,  0.0193, -0.0309]],\n",
       "              \n",
       "                       [[-0.0133,  0.0168,  0.0166],\n",
       "                        [ 0.0241,  0.0252,  0.0245],\n",
       "                        [ 0.0360,  0.0179,  0.0390]],\n",
       "              \n",
       "                       [[ 0.0052, -0.0386,  0.0413],\n",
       "                        [-0.0280, -0.0180,  0.0092],\n",
       "                        [ 0.0342,  0.0260,  0.0269]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0196,  0.0001, -0.0286],\n",
       "                        [-0.0321, -0.0369,  0.0339],\n",
       "                        [ 0.0336,  0.0322, -0.0181]],\n",
       "              \n",
       "                       [[ 0.0060, -0.0323,  0.0254],\n",
       "                        [ 0.0178, -0.0203, -0.0148],\n",
       "                        [ 0.0208,  0.0132, -0.0009]],\n",
       "              \n",
       "                       [[ 0.0199,  0.0051, -0.0357],\n",
       "                        [-0.0377, -0.0317, -0.0055],\n",
       "                        [-0.0201,  0.0337,  0.0130]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0069,  0.0395, -0.0175],\n",
       "                        [-0.0313, -0.0210,  0.0117],\n",
       "                        [ 0.0075, -0.0167,  0.0345]],\n",
       "              \n",
       "                       [[-0.0028, -0.0174, -0.0156],\n",
       "                        [-0.0416,  0.0284,  0.0146],\n",
       "                        [ 0.0250, -0.0005, -0.0223]],\n",
       "              \n",
       "                       [[-0.0128, -0.0082,  0.0329],\n",
       "                        [-0.0320, -0.0091, -0.0259],\n",
       "                        [ 0.0304, -0.0317,  0.0243]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0133,  0.0003,  0.0229],\n",
       "                        [-0.0064, -0.0002, -0.0064],\n",
       "                        [ 0.0023, -0.0066, -0.0272]],\n",
       "              \n",
       "                       [[-0.0320,  0.0236,  0.0010],\n",
       "                        [-0.0214, -0.0024,  0.0068],\n",
       "                        [ 0.0077, -0.0162, -0.0140]],\n",
       "              \n",
       "                       [[ 0.0370, -0.0239,  0.0202],\n",
       "                        [-0.0115,  0.0032,  0.0059],\n",
       "                        [-0.0390,  0.0286,  0.0294]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0198, -0.0212,  0.0054],\n",
       "                        [ 0.0013,  0.0088,  0.0323],\n",
       "                        [ 0.0320,  0.0311, -0.0269]],\n",
       "              \n",
       "                       [[ 0.0021, -0.0182, -0.0007],\n",
       "                        [-0.0245, -0.0189, -0.0037],\n",
       "                        [ 0.0264,  0.0278, -0.0375]],\n",
       "              \n",
       "                       [[-0.0207,  0.0389,  0.0190],\n",
       "                        [-0.0018, -0.0197,  0.0374],\n",
       "                        [-0.0251,  0.0192, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0378,  0.0105, -0.0080],\n",
       "                        [-0.0233, -0.0039,  0.0326],\n",
       "                        [ 0.0170, -0.0057,  0.0321]],\n",
       "              \n",
       "                       [[-0.0319,  0.0126,  0.0350],\n",
       "                        [ 0.0155,  0.0259, -0.0254],\n",
       "                        [-0.0039,  0.0352,  0.0102]],\n",
       "              \n",
       "                       [[ 0.0368, -0.0005,  0.0204],\n",
       "                        [-0.0273, -0.0030, -0.0029],\n",
       "                        [-0.0112, -0.0121, -0.0332]]]])),\n",
       "             ('encoder.encoder.1.0.bias',\n",
       "              tensor([-0.0296,  0.0035,  0.0201, -0.0302, -0.0307,  0.0289,  0.0005, -0.0201,\n",
       "                       0.0062,  0.0099, -0.0327, -0.0172, -0.0138,  0.0128, -0.0187,  0.0395,\n",
       "                      -0.0350, -0.0289,  0.0366, -0.0186,  0.0317, -0.0339,  0.0163, -0.0044,\n",
       "                       0.0183, -0.0336, -0.0202, -0.0269,  0.0274,  0.0051, -0.0295,  0.0369,\n",
       "                      -0.0349, -0.0335,  0.0092,  0.0236, -0.0063,  0.0230,  0.0044,  0.0040,\n",
       "                      -0.0092,  0.0248,  0.0206, -0.0187,  0.0139,  0.0165,  0.0310,  0.0012,\n",
       "                      -0.0293,  0.0060, -0.0123,  0.0210,  0.0203, -0.0255, -0.0077,  0.0031,\n",
       "                      -0.0262, -0.0187, -0.0329,  0.0213, -0.0244, -0.0162, -0.0243, -0.0338])),\n",
       "             ('encoder.encoder.1.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.1.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.1.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.1.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.1.1.num_batches_tracked', tensor(0)),\n",
       "             ('encoder.encoder.2.0.weight',\n",
       "              tensor([[[[-0.0397,  0.0061,  0.0397],\n",
       "                        [ 0.0027, -0.0184, -0.0159],\n",
       "                        [ 0.0336, -0.0030, -0.0002]],\n",
       "              \n",
       "                       [[-0.0402, -0.0082,  0.0302],\n",
       "                        [ 0.0326,  0.0387,  0.0128],\n",
       "                        [ 0.0131, -0.0132,  0.0397]],\n",
       "              \n",
       "                       [[-0.0345, -0.0066, -0.0327],\n",
       "                        [-0.0143,  0.0053,  0.0293],\n",
       "                        [ 0.0027,  0.0167,  0.0106]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0384, -0.0410, -0.0295],\n",
       "                        [ 0.0005,  0.0258, -0.0143],\n",
       "                        [ 0.0054, -0.0377, -0.0234]],\n",
       "              \n",
       "                       [[-0.0082,  0.0388, -0.0342],\n",
       "                        [ 0.0023, -0.0196, -0.0221],\n",
       "                        [ 0.0164, -0.0052,  0.0287]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0003,  0.0317],\n",
       "                        [-0.0027,  0.0018, -0.0229],\n",
       "                        [ 0.0386,  0.0416,  0.0377]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0025, -0.0268,  0.0008],\n",
       "                        [ 0.0340, -0.0131,  0.0189],\n",
       "                        [ 0.0064,  0.0393, -0.0140]],\n",
       "              \n",
       "                       [[-0.0303,  0.0103, -0.0213],\n",
       "                        [ 0.0066, -0.0135,  0.0382],\n",
       "                        [ 0.0028, -0.0409, -0.0269]],\n",
       "              \n",
       "                       [[ 0.0287,  0.0397, -0.0090],\n",
       "                        [-0.0122,  0.0307,  0.0015],\n",
       "                        [-0.0333,  0.0210, -0.0213]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0280, -0.0388, -0.0006],\n",
       "                        [ 0.0132, -0.0078,  0.0375],\n",
       "                        [-0.0346, -0.0118, -0.0247]],\n",
       "              \n",
       "                       [[ 0.0252,  0.0328,  0.0318],\n",
       "                        [ 0.0373,  0.0261, -0.0089],\n",
       "                        [-0.0159,  0.0411,  0.0291]],\n",
       "              \n",
       "                       [[ 0.0166, -0.0381,  0.0161],\n",
       "                        [ 0.0150,  0.0148,  0.0036],\n",
       "                        [ 0.0028, -0.0257,  0.0271]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0085,  0.0358,  0.0325],\n",
       "                        [ 0.0158, -0.0123,  0.0194],\n",
       "                        [-0.0197, -0.0132,  0.0120]],\n",
       "              \n",
       "                       [[ 0.0092, -0.0112,  0.0280],\n",
       "                        [ 0.0114, -0.0005,  0.0339],\n",
       "                        [-0.0208, -0.0332, -0.0098]],\n",
       "              \n",
       "                       [[ 0.0361,  0.0327,  0.0107],\n",
       "                        [-0.0219,  0.0267, -0.0181],\n",
       "                        [-0.0091,  0.0398, -0.0077]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0202, -0.0146,  0.0210],\n",
       "                        [ 0.0115,  0.0042,  0.0396],\n",
       "                        [-0.0358,  0.0199,  0.0168]],\n",
       "              \n",
       "                       [[-0.0226, -0.0015, -0.0239],\n",
       "                        [-0.0089, -0.0012,  0.0159],\n",
       "                        [-0.0264, -0.0141,  0.0219]],\n",
       "              \n",
       "                       [[-0.0306,  0.0027,  0.0022],\n",
       "                        [-0.0221,  0.0297, -0.0232],\n",
       "                        [ 0.0300, -0.0050,  0.0189]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0390,  0.0411, -0.0299],\n",
       "                        [-0.0243,  0.0186, -0.0160],\n",
       "                        [ 0.0167,  0.0370,  0.0077]],\n",
       "              \n",
       "                       [[-0.0415, -0.0310,  0.0250],\n",
       "                        [ 0.0152, -0.0082, -0.0096],\n",
       "                        [ 0.0292, -0.0088, -0.0013]],\n",
       "              \n",
       "                       [[-0.0210,  0.0206,  0.0053],\n",
       "                        [-0.0410, -0.0153,  0.0404],\n",
       "                        [ 0.0047, -0.0335, -0.0341]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0135,  0.0120,  0.0097],\n",
       "                        [-0.0161,  0.0156, -0.0219],\n",
       "                        [-0.0134,  0.0186,  0.0407]],\n",
       "              \n",
       "                       [[ 0.0265,  0.0312, -0.0189],\n",
       "                        [-0.0213, -0.0301,  0.0137],\n",
       "                        [-0.0216,  0.0131, -0.0344]],\n",
       "              \n",
       "                       [[ 0.0278, -0.0175,  0.0351],\n",
       "                        [-0.0351,  0.0385,  0.0015],\n",
       "                        [ 0.0198, -0.0101,  0.0115]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0361, -0.0379, -0.0329],\n",
       "                        [-0.0240,  0.0243, -0.0243],\n",
       "                        [-0.0338,  0.0071, -0.0005]],\n",
       "              \n",
       "                       [[ 0.0103, -0.0393,  0.0307],\n",
       "                        [-0.0191,  0.0317, -0.0388],\n",
       "                        [-0.0100, -0.0192, -0.0367]],\n",
       "              \n",
       "                       [[-0.0316, -0.0197,  0.0343],\n",
       "                        [ 0.0227,  0.0308,  0.0075],\n",
       "                        [ 0.0398, -0.0007,  0.0078]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0236,  0.0319, -0.0094],\n",
       "                        [-0.0151,  0.0182,  0.0323],\n",
       "                        [-0.0198, -0.0097, -0.0174]],\n",
       "              \n",
       "                       [[ 0.0297,  0.0026,  0.0231],\n",
       "                        [ 0.0219, -0.0286, -0.0107],\n",
       "                        [-0.0192, -0.0387, -0.0249]],\n",
       "              \n",
       "                       [[ 0.0369, -0.0137, -0.0225],\n",
       "                        [ 0.0218, -0.0101,  0.0111],\n",
       "                        [-0.0362, -0.0287, -0.0254]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0395,  0.0181,  0.0258],\n",
       "                        [ 0.0176, -0.0118, -0.0004],\n",
       "                        [-0.0244, -0.0371,  0.0049]],\n",
       "              \n",
       "                       [[ 0.0129,  0.0161,  0.0380],\n",
       "                        [ 0.0411,  0.0292,  0.0244],\n",
       "                        [-0.0273, -0.0353, -0.0335]],\n",
       "              \n",
       "                       [[-0.0336,  0.0401, -0.0108],\n",
       "                        [ 0.0107,  0.0191,  0.0216],\n",
       "                        [ 0.0403,  0.0379,  0.0200]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0187,  0.0311, -0.0381],\n",
       "                        [ 0.0413, -0.0394,  0.0311],\n",
       "                        [-0.0046,  0.0273,  0.0324]],\n",
       "              \n",
       "                       [[ 0.0085, -0.0325, -0.0403],\n",
       "                        [-0.0275, -0.0182, -0.0187],\n",
       "                        [ 0.0375,  0.0163,  0.0323]],\n",
       "              \n",
       "                       [[ 0.0306,  0.0114, -0.0085],\n",
       "                        [ 0.0086,  0.0168,  0.0039],\n",
       "                        [-0.0282, -0.0363,  0.0071]]]])),\n",
       "             ('encoder.encoder.2.0.bias',\n",
       "              tensor([ 0.0040,  0.0326, -0.0188,  0.0322, -0.0300, -0.0383,  0.0214,  0.0014,\n",
       "                      -0.0250,  0.0093, -0.0083, -0.0033,  0.0379, -0.0239, -0.0140,  0.0287,\n",
       "                      -0.0312, -0.0022, -0.0334, -0.0275,  0.0156,  0.0106, -0.0193, -0.0330,\n",
       "                       0.0284,  0.0065, -0.0228,  0.0130,  0.0093,  0.0118, -0.0325,  0.0156,\n",
       "                      -0.0137, -0.0041,  0.0175, -0.0413,  0.0212,  0.0256, -0.0249, -0.0167,\n",
       "                      -0.0006, -0.0297, -0.0245,  0.0255,  0.0046, -0.0266,  0.0373, -0.0392,\n",
       "                       0.0266,  0.0407,  0.0085,  0.0212, -0.0027,  0.0109, -0.0219,  0.0109,\n",
       "                       0.0020,  0.0377,  0.0262, -0.0247,  0.0065,  0.0357, -0.0396, -0.0193])),\n",
       "             ('encoder.encoder.2.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.2.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.2.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.2.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.2.1.num_batches_tracked', tensor(0)),\n",
       "             ('encoder.encoder.3.0.weight',\n",
       "              tensor([[[[-1.1976e-02, -3.3496e-02,  1.3863e-02],\n",
       "                        [ 1.2609e-02,  6.7252e-04,  3.0142e-02],\n",
       "                        [ 1.6615e-02,  2.1247e-02,  1.7045e-02]],\n",
       "              \n",
       "                       [[ 1.0323e-02, -2.3785e-02, -1.5104e-02],\n",
       "                        [ 2.7492e-02,  2.6951e-02,  2.1306e-03],\n",
       "                        [-1.9239e-02,  2.0993e-02,  1.1131e-02]],\n",
       "              \n",
       "                       [[-1.6952e-02, -4.1207e-02, -3.1862e-03],\n",
       "                        [ 3.3522e-02, -2.6141e-02, -9.4246e-03],\n",
       "                        [-1.0547e-02,  1.1244e-03,  3.5197e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.5661e-02, -3.3152e-02, -3.2404e-02],\n",
       "                        [ 3.8433e-02, -1.5856e-02, -3.7155e-02],\n",
       "                        [-3.9062e-02,  3.1343e-02, -3.5415e-02]],\n",
       "              \n",
       "                       [[-1.6467e-02, -1.1557e-02, -3.7845e-02],\n",
       "                        [-2.3409e-03, -4.0603e-02, -3.8351e-02],\n",
       "                        [ 1.6917e-03,  3.0230e-02, -1.2232e-02]],\n",
       "              \n",
       "                       [[-3.7422e-02,  8.9069e-03, -1.8543e-02],\n",
       "                        [ 3.1089e-02,  1.9628e-02, -1.7963e-02],\n",
       "                        [ 5.3029e-03,  1.5585e-02, -6.8359e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9724e-02, -3.9518e-02,  2.6039e-02],\n",
       "                        [-1.2687e-02,  1.6310e-02, -1.7672e-02],\n",
       "                        [ 3.7650e-02,  3.8580e-02,  2.3176e-02]],\n",
       "              \n",
       "                       [[ 1.0208e-02,  2.3332e-02, -1.9001e-02],\n",
       "                        [-3.4304e-02, -4.1108e-02, -1.0649e-02],\n",
       "                        [ 3.3719e-02,  3.0197e-02,  1.2036e-02]],\n",
       "              \n",
       "                       [[-2.1789e-02,  1.0318e-02, -1.4979e-02],\n",
       "                        [ 3.0908e-03,  2.8231e-02, -3.8949e-02],\n",
       "                        [ 1.1377e-02,  3.6438e-02, -4.0597e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4500e-02,  3.4581e-02, -8.8641e-03],\n",
       "                        [ 9.4617e-03,  4.0239e-03, -3.4163e-02],\n",
       "                        [ 3.7571e-02,  3.6595e-02,  2.7929e-03]],\n",
       "              \n",
       "                       [[ 7.5803e-03,  1.1123e-02, -1.3546e-03],\n",
       "                        [-1.3530e-02,  2.8978e-02,  1.2934e-03],\n",
       "                        [ 2.6988e-02,  3.8602e-03,  1.0790e-02]],\n",
       "              \n",
       "                       [[ 3.5626e-02, -5.1991e-03,  3.8743e-03],\n",
       "                        [-1.0661e-02, -2.9826e-02, -2.2242e-02],\n",
       "                        [ 3.8268e-02,  1.1027e-02,  9.8819e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7807e-02,  3.4668e-02, -2.6453e-02],\n",
       "                        [ 1.3964e-02, -2.1374e-02, -2.6660e-02],\n",
       "                        [-3.8283e-03, -6.7112e-03, -1.8102e-02]],\n",
       "              \n",
       "                       [[ 3.8566e-02, -3.4343e-02, -2.3497e-03],\n",
       "                        [ 3.9419e-02,  3.7875e-03,  2.6144e-02],\n",
       "                        [-2.4148e-02, -3.8834e-02, -2.0416e-02]],\n",
       "              \n",
       "                       [[ 1.8296e-02,  3.5391e-02, -3.4034e-02],\n",
       "                        [ 3.5875e-02, -6.5203e-03,  1.8008e-02],\n",
       "                        [-3.6947e-02,  1.0150e-02, -4.0338e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2125e-02, -1.4545e-02,  3.0849e-02],\n",
       "                        [-1.7923e-02, -5.0295e-03, -2.4586e-02],\n",
       "                        [ 2.5509e-02,  2.1551e-02,  3.2833e-03]],\n",
       "              \n",
       "                       [[-1.6404e-03, -3.2500e-02,  3.4553e-02],\n",
       "                        [-1.2924e-02, -1.6315e-02,  1.0406e-02],\n",
       "                        [-2.4069e-02,  2.0262e-03, -3.7136e-02]],\n",
       "              \n",
       "                       [[-2.3765e-02, -9.9572e-03,  5.5192e-03],\n",
       "                        [ 9.4250e-03, -5.0191e-04,  6.4252e-03],\n",
       "                        [ 1.9730e-03,  1.1555e-02, -4.1486e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0203e-02, -7.0559e-03,  4.0208e-02],\n",
       "                        [-5.2816e-03,  1.3269e-02, -3.9501e-02],\n",
       "                        [ 2.2322e-02, -3.4971e-02, -1.8936e-02]],\n",
       "              \n",
       "                       [[-3.5225e-02, -1.5194e-02,  2.8617e-02],\n",
       "                        [ 2.7312e-02,  3.2598e-02,  2.8545e-02],\n",
       "                        [-7.6005e-03,  7.0084e-04,  1.0681e-02]],\n",
       "              \n",
       "                       [[ 6.6430e-03, -1.1440e-02,  5.3447e-03],\n",
       "                        [-9.6522e-03,  3.6576e-02,  1.0434e-03],\n",
       "                        [ 1.2800e-02, -3.8971e-02, -2.4852e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.5268e-02,  2.1137e-03,  2.3594e-02],\n",
       "                        [-3.3830e-02,  1.8754e-02,  3.1891e-02],\n",
       "                        [-1.1958e-02, -8.2001e-03, -7.9147e-04]],\n",
       "              \n",
       "                       [[ 7.8471e-03, -2.8674e-02,  3.8783e-02],\n",
       "                        [ 2.9367e-02, -1.6656e-02,  3.4870e-02],\n",
       "                        [-9.0140e-03, -2.9242e-02,  4.0273e-02]],\n",
       "              \n",
       "                       [[ 2.3911e-02, -1.3815e-02,  2.8704e-02],\n",
       "                        [ 3.2895e-02, -3.9945e-02, -3.3715e-02],\n",
       "                        [-3.6008e-02, -1.9243e-03,  2.4693e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6585e-02,  2.2075e-02, -3.0239e-02],\n",
       "                        [ 1.4058e-02, -7.5748e-03, -3.7489e-02],\n",
       "                        [ 2.7510e-02, -3.7114e-02,  3.5775e-02]],\n",
       "              \n",
       "                       [[-2.2060e-02, -3.9018e-02,  2.6021e-03],\n",
       "                        [ 2.9356e-02,  2.1078e-02, -6.0794e-03],\n",
       "                        [-1.9190e-02,  1.7997e-02,  3.0364e-03]],\n",
       "              \n",
       "                       [[-7.8680e-04,  2.9437e-02,  2.9911e-03],\n",
       "                        [ 1.6931e-02, -3.4874e-02, -2.9449e-02],\n",
       "                        [ 1.5189e-02,  2.4800e-02, -3.9556e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.6393e-02,  2.0521e-02, -2.8383e-03],\n",
       "                        [ 2.5707e-02, -2.0589e-02,  3.4570e-02],\n",
       "                        [-2.5078e-03,  2.2663e-02,  8.5728e-03]],\n",
       "              \n",
       "                       [[ 2.2791e-02, -3.6645e-02, -9.4959e-03],\n",
       "                        [-3.8591e-02,  1.6200e-02, -1.8642e-02],\n",
       "                        [-2.3496e-02, -1.8415e-02, -1.0703e-02]],\n",
       "              \n",
       "                       [[ 2.7858e-02,  8.3426e-03,  2.0863e-02],\n",
       "                        [ 5.2012e-03, -3.6532e-02, -3.8685e-02],\n",
       "                        [ 1.6097e-03,  6.1710e-03,  2.2144e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8004e-02, -2.8430e-02,  3.5174e-02],\n",
       "                        [-8.8423e-04,  6.7052e-03, -5.7291e-03],\n",
       "                        [ 1.3556e-02, -2.6776e-02,  4.5960e-03]],\n",
       "              \n",
       "                       [[ 3.0607e-02, -2.7951e-02,  2.1951e-02],\n",
       "                        [-3.2605e-02, -2.1886e-02,  2.1721e-02],\n",
       "                        [-1.6683e-02, -1.9102e-03, -1.4759e-02]],\n",
       "              \n",
       "                       [[-5.1496e-03,  1.3790e-02, -1.9329e-02],\n",
       "                        [ 3.0243e-02,  3.8225e-02, -3.9222e-02],\n",
       "                        [ 2.5744e-03,  2.9253e-02,  3.2404e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.6017e-03,  3.1190e-02, -3.6674e-02],\n",
       "                        [ 3.1675e-02,  3.3391e-02, -1.9574e-03],\n",
       "                        [-3.4931e-03, -3.8393e-02,  1.4137e-03]],\n",
       "              \n",
       "                       [[-5.7077e-03, -1.2149e-02,  2.2492e-02],\n",
       "                        [-4.1024e-03,  3.4306e-02,  2.4160e-02],\n",
       "                        [ 2.8756e-02, -2.4067e-03, -1.8845e-02]],\n",
       "              \n",
       "                       [[-3.2353e-02, -7.5967e-03, -3.7086e-02],\n",
       "                        [ 1.8801e-02,  1.1921e-06,  9.5928e-03],\n",
       "                        [-2.2686e-02,  3.4416e-02,  7.7885e-03]]]])),\n",
       "             ('encoder.encoder.3.0.bias',\n",
       "              tensor([-0.0413, -0.0204, -0.0250,  0.0067, -0.0008, -0.0110, -0.0192, -0.0264,\n",
       "                      -0.0088,  0.0376, -0.0087,  0.0131, -0.0325,  0.0132,  0.0357,  0.0345,\n",
       "                      -0.0296, -0.0177,  0.0294,  0.0023,  0.0318, -0.0110,  0.0261, -0.0024,\n",
       "                      -0.0121, -0.0199,  0.0033,  0.0245, -0.0259, -0.0103,  0.0217,  0.0156,\n",
       "                       0.0265, -0.0234, -0.0035,  0.0211,  0.0335, -0.0105,  0.0053, -0.0160,\n",
       "                      -0.0317, -0.0220,  0.0175, -0.0301, -0.0372, -0.0158, -0.0387, -0.0277,\n",
       "                      -0.0206,  0.0378, -0.0191, -0.0126,  0.0038, -0.0334, -0.0084,  0.0238,\n",
       "                       0.0249,  0.0251,  0.0211, -0.0340, -0.0178,  0.0395,  0.0220,  0.0352])),\n",
       "             ('encoder.encoder.3.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.3.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.3.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.encoder.3.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.encoder.3.1.num_batches_tracked', tensor(0)),\n",
       "             ('classifier.0.weight',\n",
       "              tensor([[-0.0414, -0.0317, -0.0197, -0.0564,  0.0007, -0.0751, -0.0725, -0.0063,\n",
       "                       -0.0568, -0.0617,  0.1010,  0.0197, -0.0668,  0.0256,  0.0584, -0.0374,\n",
       "                        0.0020, -0.0525, -0.0141, -0.0876, -0.0817, -0.1030,  0.0231,  0.0031,\n",
       "                       -0.0790, -0.0755, -0.1066, -0.0999,  0.0011,  0.0899,  0.0323, -0.0932,\n",
       "                        0.0735,  0.0243, -0.0836,  0.0821, -0.0990, -0.0204,  0.0416,  0.0452,\n",
       "                        0.0187, -0.1112, -0.0263, -0.0883,  0.0450, -0.0943,  0.0772,  0.0458,\n",
       "                       -0.0889, -0.0917,  0.0026, -0.0644, -0.0338,  0.0422,  0.0472,  0.0283,\n",
       "                       -0.0500, -0.0339, -0.1012,  0.0354,  0.0638,  0.0979,  0.0164, -0.0068,\n",
       "                        0.0096,  0.0813, -0.0060,  0.0852, -0.0208, -0.0363,  0.0893,  0.0015,\n",
       "                        0.0271, -0.0445, -0.0271,  0.0171, -0.0375,  0.0773,  0.0512, -0.0457],\n",
       "                      [-0.0746, -0.0443, -0.0067,  0.0126,  0.0302,  0.0462, -0.0471, -0.0421,\n",
       "                       -0.1107, -0.0315,  0.0923,  0.0039,  0.1066, -0.0069, -0.0528, -0.0065,\n",
       "                        0.0062,  0.0413,  0.0807, -0.0471,  0.0278,  0.1117,  0.1049,  0.0852,\n",
       "                       -0.0911,  0.0655, -0.0813, -0.0802,  0.0231,  0.0865, -0.0181, -0.0506,\n",
       "                        0.0989, -0.1029, -0.0639, -0.0895,  0.0377,  0.0137, -0.0481,  0.0765,\n",
       "                        0.0648,  0.0472, -0.1095, -0.0098, -0.1047, -0.0531, -0.0183, -0.0357,\n",
       "                       -0.0836,  0.1100, -0.0214,  0.0966, -0.1047, -0.0319, -0.0560, -0.0431,\n",
       "                        0.0067, -0.0011,  0.0553,  0.0034, -0.0237,  0.0614,  0.0213, -0.1025,\n",
       "                       -0.0906,  0.1046, -0.1011,  0.0995, -0.0731, -0.0836, -0.0255, -0.0794,\n",
       "                        0.0667,  0.0715,  0.0768, -0.0361, -0.0138,  0.0288,  0.0969,  0.0820],\n",
       "                      [-0.0222, -0.0599, -0.0588,  0.0756,  0.0586,  0.0087,  0.0299,  0.0055,\n",
       "                       -0.0681, -0.0249, -0.0114,  0.0481, -0.0552,  0.1071, -0.0378, -0.1056,\n",
       "                        0.0110,  0.0068, -0.0187,  0.0842,  0.0253, -0.0157,  0.0464,  0.1086,\n",
       "                        0.0907, -0.0097,  0.0904,  0.0740,  0.0972, -0.0035, -0.0224,  0.0160,\n",
       "                        0.0916, -0.0870, -0.0410,  0.0749,  0.0632, -0.0223, -0.0937,  0.0494,\n",
       "                       -0.0250,  0.0934,  0.0724, -0.0928,  0.1025,  0.0820, -0.0388, -0.0423,\n",
       "                        0.1084,  0.1018,  0.0186,  0.1078, -0.0849, -0.0915,  0.0905,  0.0813,\n",
       "                       -0.0897, -0.0874, -0.1052, -0.0559,  0.0940, -0.0338, -0.0156,  0.0137,\n",
       "                        0.0611,  0.0036,  0.0086,  0.1098,  0.0231,  0.0516, -0.0393,  0.0077,\n",
       "                        0.0968, -0.0878, -0.0800, -0.0533,  0.0042, -0.0578,  0.1103, -0.0690],\n",
       "                      [-0.1055,  0.0897, -0.0005, -0.0485,  0.0964,  0.0287,  0.0534,  0.0932,\n",
       "                        0.0546, -0.1096,  0.1015, -0.0256,  0.0797,  0.0760,  0.0988,  0.0481,\n",
       "                       -0.0211,  0.0041,  0.0809, -0.1079,  0.0905,  0.0180,  0.1054,  0.0930,\n",
       "                       -0.0744, -0.0552, -0.0353,  0.0089,  0.0590,  0.0676,  0.0846,  0.0129,\n",
       "                        0.0633, -0.0760, -0.0413,  0.0861, -0.1027,  0.0212, -0.0358, -0.0444,\n",
       "                        0.0117, -0.0599, -0.0221,  0.0217, -0.1103,  0.0116,  0.0231, -0.0471,\n",
       "                        0.0862, -0.0763,  0.0465, -0.0271, -0.0985, -0.0698,  0.0242,  0.0387,\n",
       "                       -0.0585,  0.1089, -0.1062,  0.0442,  0.0597,  0.1080,  0.0477, -0.0169,\n",
       "                        0.0340,  0.0858,  0.0341, -0.0834, -0.1092,  0.0635, -0.0912,  0.1083,\n",
       "                        0.0727,  0.0638,  0.0664,  0.0264,  0.0449,  0.0564, -0.0391, -0.0673],\n",
       "                      [ 0.0011,  0.1069,  0.1054, -0.0087, -0.1038,  0.0091,  0.0184,  0.0790,\n",
       "                       -0.0525, -0.0190,  0.0476,  0.0793, -0.0158,  0.0125, -0.0763, -0.0371,\n",
       "                        0.0131, -0.0309,  0.0245,  0.1094, -0.0037, -0.0704, -0.0795,  0.0108,\n",
       "                        0.0269,  0.0569, -0.0608, -0.0732,  0.0927,  0.0236, -0.0643,  0.0575,\n",
       "                        0.1062, -0.0981, -0.0188,  0.0905, -0.0073, -0.0022, -0.0195,  0.0454,\n",
       "                       -0.0528, -0.0382, -0.0328,  0.0108,  0.0977,  0.0349,  0.0004,  0.0094,\n",
       "                        0.0110,  0.0120,  0.0968, -0.0805,  0.0253, -0.0100, -0.0973,  0.0675,\n",
       "                        0.0310, -0.0570, -0.0007, -0.0634,  0.0545,  0.0833,  0.0070, -0.0075,\n",
       "                        0.0781, -0.0190, -0.0727, -0.0251, -0.0946, -0.0257, -0.0863,  0.0962,\n",
       "                       -0.0897, -0.0924, -0.0019, -0.0718, -0.0585,  0.0851,  0.0051, -0.0834],\n",
       "                      [-0.0771, -0.0492, -0.0283,  0.0734, -0.1039,  0.0690,  0.0268, -0.0305,\n",
       "                        0.0349,  0.0425, -0.0732, -0.0225, -0.0260, -0.0168,  0.0696,  0.0596,\n",
       "                       -0.0447, -0.0803, -0.0464,  0.0957,  0.0776,  0.0358, -0.0378,  0.0866,\n",
       "                        0.0717,  0.0935,  0.0878,  0.1077, -0.1039,  0.0424, -0.0885, -0.0850,\n",
       "                       -0.0519, -0.0949, -0.0992,  0.0587, -0.0620, -0.0299,  0.0131, -0.0780,\n",
       "                       -0.0635, -0.0963, -0.0680, -0.0740, -0.0784, -0.0140,  0.0974,  0.0999,\n",
       "                        0.1116,  0.0878, -0.0146, -0.0898, -0.0004, -0.0793,  0.0806, -0.0118,\n",
       "                       -0.0647,  0.0803, -0.0019,  0.0161, -0.0777, -0.0681,  0.0139,  0.0323,\n",
       "                        0.0352, -0.0593,  0.1084, -0.0161, -0.0820,  0.0240, -0.0190,  0.0709,\n",
       "                        0.0748, -0.0390,  0.0286,  0.0559,  0.0763,  0.0217, -0.0022,  0.0773],\n",
       "                      [-0.0463, -0.0506,  0.0611,  0.1089,  0.0014, -0.1015,  0.0403,  0.0342,\n",
       "                       -0.0151,  0.0477,  0.0774, -0.0128,  0.0927,  0.0344,  0.1091,  0.0240,\n",
       "                        0.0406,  0.0700, -0.0276,  0.0411,  0.0343, -0.0548,  0.0269, -0.0266,\n",
       "                        0.0808,  0.1059,  0.0166, -0.0841,  0.0650, -0.0278, -0.0849, -0.0315,\n",
       "                        0.0380,  0.0321, -0.1039, -0.0766,  0.0320, -0.0791, -0.0562, -0.0805,\n",
       "                       -0.0400, -0.0406, -0.0662,  0.0217,  0.1100,  0.0117, -0.0674,  0.1109,\n",
       "                        0.0733, -0.0010,  0.0548, -0.0218, -0.0141, -0.0340,  0.0540,  0.0753,\n",
       "                        0.0663,  0.1082,  0.1104, -0.0778,  0.0180,  0.0784, -0.0194, -0.0754,\n",
       "                       -0.0160, -0.0961,  0.0785, -0.0391,  0.0810,  0.0281,  0.0377,  0.0956,\n",
       "                       -0.0451, -0.0816,  0.0195,  0.0277, -0.0967, -0.0947, -0.0499, -0.0827],\n",
       "                      [ 0.0773,  0.0384, -0.0592, -0.0670,  0.0697,  0.0290, -0.0331,  0.0429,\n",
       "                       -0.0275, -0.0381,  0.0951,  0.0797, -0.0119,  0.0472, -0.0005, -0.0800,\n",
       "                        0.0776, -0.0857, -0.0471, -0.0617,  0.0586,  0.0183,  0.0705, -0.0018,\n",
       "                       -0.0631, -0.0676,  0.0302,  0.0300, -0.0829, -0.0204,  0.0664, -0.0908,\n",
       "                       -0.0058,  0.0411, -0.0203,  0.1114, -0.0317,  0.0094,  0.1001, -0.0250,\n",
       "                        0.0171, -0.0014, -0.1071, -0.0595,  0.0216,  0.1093,  0.0154, -0.0704,\n",
       "                       -0.0469, -0.0937,  0.0848, -0.0306,  0.0690, -0.0548,  0.0307, -0.0084,\n",
       "                       -0.0494,  0.0914, -0.0357, -0.0401, -0.0867, -0.0465,  0.0508, -0.0323,\n",
       "                       -0.0801, -0.0397,  0.0458,  0.0578,  0.0050, -0.0536,  0.0224,  0.0406,\n",
       "                        0.0574, -0.0430,  0.0092,  0.0591, -0.0593, -0.0565,  0.1020, -0.0547],\n",
       "                      [-0.0624, -0.0628,  0.0859,  0.1110, -0.0076, -0.0044, -0.0889, -0.0954,\n",
       "                       -0.0073, -0.0532,  0.0835,  0.0322,  0.0209, -0.0329,  0.0647, -0.0600,\n",
       "                       -0.0500,  0.0241,  0.0335, -0.0078,  0.0497,  0.0230, -0.0347,  0.0415,\n",
       "                       -0.1014, -0.0623,  0.0972, -0.0478,  0.0110, -0.0076,  0.0821,  0.0314,\n",
       "                       -0.0765,  0.0034,  0.0253, -0.0888,  0.0898,  0.0113,  0.0334, -0.0066,\n",
       "                       -0.0179,  0.0906, -0.0109,  0.0359, -0.0808, -0.1025,  0.0161, -0.0230,\n",
       "                       -0.0871, -0.0072,  0.0787, -0.0502,  0.0591,  0.0914, -0.0149,  0.0296,\n",
       "                        0.0542,  0.1005,  0.0359, -0.0070,  0.0700, -0.0389, -0.0879,  0.0526,\n",
       "                        0.1031,  0.0036,  0.0737,  0.0418, -0.0550, -0.1116,  0.0664,  0.0946,\n",
       "                       -0.0048, -0.0635,  0.0024, -0.0828, -0.0999, -0.0205, -0.1020,  0.0406],\n",
       "                      [-0.0168,  0.0379,  0.0953, -0.0838, -0.1037,  0.1068,  0.0824, -0.0348,\n",
       "                        0.1006, -0.0359,  0.0759,  0.0902, -0.0673, -0.0746, -0.0978,  0.1056,\n",
       "                        0.0425,  0.0862,  0.1028, -0.0746,  0.0801, -0.0309, -0.0346, -0.0267,\n",
       "                        0.0850, -0.0977,  0.1008, -0.0401, -0.0661, -0.0452,  0.0286,  0.0074,\n",
       "                        0.0027,  0.1073,  0.0742,  0.0960, -0.0677, -0.0324,  0.0368, -0.0534,\n",
       "                       -0.0944, -0.0008, -0.0174,  0.0563,  0.0676,  0.0444, -0.0963,  0.0417,\n",
       "                       -0.1073, -0.0536, -0.0068,  0.1006,  0.0101, -0.0196,  0.0121, -0.0236,\n",
       "                        0.1014,  0.0491, -0.0608, -0.0612, -0.1016, -0.0732,  0.1039,  0.0461,\n",
       "                        0.0188, -0.0935,  0.0324,  0.0787, -0.0049,  0.0812,  0.0796, -0.0351,\n",
       "                        0.0928, -0.0666, -0.0782, -0.0426,  0.0708, -0.1027, -0.0042, -0.0954]])),\n",
       "             ('classifier.0.bias',\n",
       "              tensor([ 0.0778, -0.0736,  0.0683,  0.0393, -0.0785, -0.0377, -0.0878,  0.1056,\n",
       "                      -0.0658, -0.0814])),\n",
       "             ('classifier.2.weight',\n",
       "              tensor([[ 0.1403,  0.2493,  0.2501, -0.2176,  0.0770, -0.1270, -0.1564, -0.1605,\n",
       "                        0.1291, -0.1433],\n",
       "                      [ 0.2325,  0.0713, -0.2173,  0.0758, -0.1464, -0.0200, -0.1532,  0.2638,\n",
       "                        0.1200, -0.1980],\n",
       "                      [-0.0459, -0.2695, -0.0932,  0.1131,  0.2590, -0.1208,  0.0857, -0.2528,\n",
       "                        0.1219, -0.2381],\n",
       "                      [-0.1865,  0.1857, -0.2668, -0.2263, -0.2239,  0.1249,  0.2026, -0.2201,\n",
       "                        0.1372,  0.2704],\n",
       "                      [-0.2182, -0.1434, -0.3018,  0.2458,  0.2130,  0.3073,  0.0717, -0.0262,\n",
       "                       -0.0301, -0.2563]])),\n",
       "             ('classifier.2.bias',\n",
       "              tensor([ 0.0299, -0.1187,  0.2291, -0.0609,  0.1106])),\n",
       "             ('classifier.4.weight',\n",
       "              tensor([[ 0.0449, -0.1965, -0.2199,  0.0607, -0.1720],\n",
       "                      [-0.2675, -0.3088, -0.0839, -0.0378, -0.0900]])),\n",
       "             ('classifier.4.bias', tensor([0.1008, 0.3873]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()  # check it is non empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36653dc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811369d",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b430aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:MnistDPL,\n",
    "        encoder:Module,\n",
    "        episodic_dataloader:DataLoader,\n",
    "        unsup_train_loader:DataLoader,\n",
    "        unsup_val_loader:DataLoader,\n",
    "        _loss: ADDMNIST_DPL, \n",
    "        num_distinct_labels: int,\n",
    "        args,\n",
    "        save_folder\n",
    "    ):\n",
    "    \n",
    "    # for full reproducibility\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "    # for early stopping\n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # device configuration\n",
    "    model.to(args.device)\n",
    "\n",
    "    # Initialize the optimizer and the scheduler.\n",
    "    optimizer = torch.optim.Adam(encoder.parameters())\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # scheduler from PNets paper\n",
    "\n",
    "\n",
    "    print(\"\\n--- Start of Training ---\\n\")\n",
    "    proto_train_loss_history = []\n",
    "    proto_train_acc_history = []\n",
    "    for epoch in range(args.proto_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{args.proto_epochs}\")\n",
    "        print(\"--- Training Protonet\")\n",
    "\n",
    "        encoder.train()\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_acc = []\n",
    "        \n",
    "        # ^ PHASE 1: Training the Protonet with the episodic dataloader\n",
    "        for batch in tqdm(episodic_dataloader, total=args.iterations):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get batch images and labels\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(args.device), labels.to(args.device)\n",
    "            \n",
    "            # Forward pass: compute embeddings for all images in the episode.\n",
    "            embeddings = encoder(images)\n",
    "            \n",
    "            # Compute prototypical loss.\n",
    "            pNet_loss = PrototypicalLoss(n_support=args.num_support)\n",
    "            loss, acc = pNet_loss(input=embeddings, target=labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc.item())\n",
    "        \n",
    "        avg_loss = np.mean(epoch_loss)\n",
    "        avg_acc = np.mean(epoch_acc)\n",
    "        proto_train_loss_history.append(avg_loss)\n",
    "        proto_train_acc_history.append(avg_acc)\n",
    "        print(f\"  Avg Loss: {avg_loss:.4f} | Avg Acc: {avg_acc:.4f}\")\n",
    "\n",
    "\n",
    "        # ^ PHASE 2: Training the Protonet with the unsupervised dataloader\n",
    "        print(\"--- Training with Unsupervised Data\")\n",
    "        # ys are the predictions of the model, y_true are the true labels, cs are the predictions of the concepts, cs_true are the true concepts\n",
    "        ys, y_true, cs, cs_true = None, None, None, None\n",
    "        for i, data in enumerate(unsup_train_loader):\n",
    "            if random.random() > uns_parameter_percentage:\n",
    "                continue  # Skip this batch with probability (1 - percentage)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            images, labels, concepts = data\n",
    "            images, labels, concepts = (\n",
    "                images.to(model.device),    # input IMAGES\n",
    "                labels.to(model.device),    # ground truth LABELS\n",
    "                concepts.to(model.device),  # ground truth CONCEPTS\n",
    "            )\n",
    "\n",
    "            # Get a random support set.\n",
    "            this_support_images, this_support_labels = get_random_classes(\n",
    "                mnist_dataset.images, mnist_dataset.labels, args.n_support, num_distinct_labels)\n",
    "            assert this_support_images.shape == (args.n_support * num_distinct_labels, 1, 28, 28), \\\n",
    "                f\"Support images shape is not ({args.n_support * num_distinct_labels}, 1, 28, 28), but {this_support_images.shape}\"\n",
    "            assert this_support_labels.shape == (args.n_support * num_distinct_labels, 1), \\\n",
    "                f\"Support labels shape is not ({args.n_support * num_distinct_labels}, 1), but {this_support_labels.shape}\"\n",
    "            \n",
    "            # ^ forward pass \n",
    "            out_dict = model(images, this_support_images, this_support_labels)\n",
    "\n",
    "            ''' Enrich the out_dict with the ground truth labels and concepts '''\n",
    "            out_dict.update({\"LABELS\": labels, \"CONCEPTS\": concepts})\n",
    "\n",
    "            ''' Extract the predicted concepts for the first image in the batch '''\n",
    "            loss, losses = _loss(out_dict, args)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if ys is None:  # first iteration\n",
    "                ys = out_dict[\"YS\"]\n",
    "                y_true = out_dict[\"LABELS\"]\n",
    "                cs = out_dict[\"pCS\"]\n",
    "                cs_true = out_dict[\"CONCEPTS\"]\n",
    "            else:           # all other iterations\n",
    "                ys = torch.concatenate((ys, out_dict[\"YS\"]), dim=0)\n",
    "                y_true = torch.concatenate((y_true, out_dict[\"LABELS\"]), dim=0)\n",
    "                cs = torch.concatenate((cs, out_dict[\"pCS\"]), dim=0)\n",
    "                cs_true = torch.concatenate((cs_true, out_dict[\"CONCEPTS\"]), dim=0)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress_bar(i, len(unsup_train_loader) - 9, epoch, loss.item())\n",
    "\n",
    "\n",
    "        # Step the scheduler at the end of the epoch\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print(\"End of epoch \", epoch)\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print()\n",
    "\n",
    "        # ^ PHASE 3: Evaluation\n",
    "        if ys is None:  \n",
    "            torch.save(model.state_dict(), save_folder)\n",
    "            print(f\"Saved model after prototypical netwrork training.\")\n",
    "            print()\n",
    "            continue  # Skip evaluation if no unsupervised data was used\n",
    "        \n",
    "        # support images and labels for evaluation purposes\n",
    "        this_support_images, this_support_labels = get_random_classes(\n",
    "            mnist_dataset.images, mnist_dataset.labels, args.n_support, num_distinct_labels)\n",
    "        assert this_support_images.shape == (args.n_support * num_distinct_labels, 1, 28, 28), \\\n",
    "            f\"Support images shape is not ({args.n_support * num_distinct_labels}, 1, 28, 28), but {this_support_images.shape}\"\n",
    "        assert this_support_labels.shape == (args.n_support * num_distinct_labels, 1), \\\n",
    "            f\"Support labels shape is not ({args.n_support * num_distinct_labels}, 1), but {this_support_labels.shape}\"\n",
    "        \n",
    "        model.eval()\n",
    "        tloss, cacc, yacc, f1_y, f1_c = evaluate_metrics(model, unsup_val_loader, args, support_images=this_support_images, support_labels=this_support_labels)\n",
    "\n",
    "        ### LOGGING ###\n",
    "        fprint(\"  ACC C\", cacc, \"  ACC Y\", yacc, \"F1 Y\", f1_y, \"F1 C\", f1_c)\n",
    "        print()\n",
    "\n",
    "        if not args.tuning and f1_y > best_f1:\n",
    "            print(\"Saving...\")\n",
    "            # Update best F1 score\n",
    "            best_f1 = f1_y\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), save_folder)\n",
    "            print(f\"Saved best model with F1 score: {best_f1}\")\n",
    "            print()\n",
    "\n",
    "        elif f1_y <= best_f1:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= args.patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    print(\"End of training\")\n",
    "    return best_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e64551",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f326035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training model with seed 1415\n",
      "Chosen device: cuda\n",
      "Save path for this model:  ../notebook-outputs/mnmath/my_models/cbm/episodic-proto-net-pipeline-1.0\n",
      "Saving in folder:  ../notebook-outputs/mnmath/my_models/cbm/episodic-proto-net-pipeline-1.0/cbm_1415.pth\n",
      "\n",
      "--- Start of Training ---\n",
      "\n",
      "Epoch 1/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 47.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.1184 | Avg Acc: 0.9684\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 1.9786826372146606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:25 ] epoch 0: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.76486057"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.0839667320251465\n",
      "Concept supervision loss 2.2485575675964355\n",
      "Concept supervision loss 2.0170390605926514\n",
      "Concept supervision loss 2.1111881732940674\n",
      "Concept supervision loss 2.0046069622039795\n",
      "Concept supervision loss 1.9856775999069214\n",
      "Concept supervision loss 2.0261449813842773\n",
      "Concept supervision loss 1.9368866682052612\n",
      "Concept supervision loss 1.9852285385131836\n",
      "Concept supervision loss 2.1364803314208984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:25 ] epoch 0: |██████████████████████████████████████████████████| loss: 0.56418383"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.9683647155761719\n",
      "Concept supervision loss 2.1515285968780518\n",
      "Concept supervision loss 1.9214274883270264\n",
      "Concept supervision loss 2.0038375854492188\n",
      "Concept supervision loss 2.0032503604888916\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  0\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 41.064453125   ACC Y 68.359375 F1 Y 41.17588883944025 F1 C 24.543915804880452\n",
      "\n",
      "Saving...\n",
      "Saved best model with F1 score: 41.17588883944025\n",
      "\n",
      "Epoch 2/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 62.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0416 | Avg Acc: 0.9908\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 2.1032164096832275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:25 ] epoch 1: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.62925601"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.017348527908325\n",
      "Concept supervision loss 1.9899922609329224\n",
      "Concept supervision loss 1.9807718992233276\n",
      "Concept supervision loss 1.9472466707229614\n",
      "Concept supervision loss 1.9774278402328491\n",
      "Concept supervision loss 2.2003378868103027\n",
      "Concept supervision loss 2.0126609802246094\n",
      "Concept supervision loss 2.1177728176116943\n",
      "Concept supervision loss 2.0903308391571045\n",
      "Concept supervision loss 2.162032127380371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:25 ] epoch 1: |██████████████████████████████████████████████████| loss: 0.56518763"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.0445218086242676\n",
      "Concept supervision loss 2.3248393535614014\n",
      "Concept supervision loss 2.087418794631958\n",
      "Concept supervision loss 1.8961273431777954\n",
      "Concept supervision loss 2.062730550765991\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  1\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 52.490234375   ACC Y 70.1171875 F1 Y 46.984761366841475 F1 C 29.157068764227194\n",
      "\n",
      "Saving...\n",
      "Saved best model with F1 score: 46.984761366841475\n",
      "\n",
      "Epoch 3/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 63.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0168 | Avg Acc: 0.9956\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 2.2000935077667236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:26 ] epoch 2: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.63944048"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.019930124282837\n",
      "Concept supervision loss 1.9563829898834229\n",
      "Concept supervision loss 2.106966972351074\n",
      "Concept supervision loss 1.9697126150131226\n",
      "Concept supervision loss 2.023242235183716\n",
      "Concept supervision loss 2.0727546215057373\n",
      "Concept supervision loss 2.1312549114227295\n",
      "Concept supervision loss 2.052786111831665\n",
      "Concept supervision loss 2.0575294494628906\n",
      "Concept supervision loss 1.856406569480896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:26 ] epoch 2: |██████████████████████████████████████████████████| loss: 0.56489366"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.050544261932373\n",
      "Concept supervision loss 2.1374001502990723\n",
      "Concept supervision loss 2.125500440597534\n",
      "Concept supervision loss 2.0206594467163086\n",
      "Concept supervision loss 1.9409514665603638\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  2\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 51.416015625   ACC Y 69.140625 F1 Y 43.093139284287226 F1 C 29.959516610716353\n",
      "\n",
      "Epoch 4/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 59.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0103 | Avg Acc: 0.9968\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 2.2007250785827637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:26 ] epoch 3: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.56641281"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.9148914813995361\n",
      "Concept supervision loss 1.8943312168121338\n",
      "Concept supervision loss 1.9378607273101807\n",
      "Concept supervision loss 2.0355660915374756\n",
      "Concept supervision loss 2.068765878677368\n",
      "Concept supervision loss 1.9713579416275024\n",
      "Concept supervision loss 1.9789233207702637\n",
      "Concept supervision loss 2.0250964164733887\n",
      "Concept supervision loss 1.953564167022705\n",
      "Concept supervision loss 2.0483269691467285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:26 ] epoch 3: |██████████████████████████████████████████████████| loss: 0.51169819"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.994301199913025\n",
      "Concept supervision loss 2.323848009109497\n",
      "Concept supervision loss 1.9687135219573975\n",
      "Concept supervision loss 2.062700033187866\n",
      "Concept supervision loss 2.179992914199829\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  3\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 45.60546875   ACC Y 69.140625 F1 Y 42.05499884456209 F1 C 27.334434998539493\n",
      "\n",
      "Epoch 5/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 64.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0124 | Avg Acc: 0.9964\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 1.9868077039718628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:26 ] epoch 4: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.73770905"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.0261592864990234\n",
      "Concept supervision loss 2.0229790210723877\n",
      "Concept supervision loss 2.008888006210327\n",
      "Concept supervision loss 2.0944674015045166\n",
      "Concept supervision loss 1.9386787414550781\n",
      "Concept supervision loss 1.778847098350525\n",
      "Concept supervision loss 1.9455175399780273\n",
      "Concept supervision loss 2.0216100215911865\n",
      "Concept supervision loss 1.9109171628952026\n",
      "Concept supervision loss 2.135277032852173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:27 ] epoch 4: |██████████████████████████████████████████████████| loss: 0.54907113"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.885748028755188\n",
      "Concept supervision loss 1.911771297454834\n",
      "Concept supervision loss 2.1771607398986816\n",
      "Concept supervision loss 2.1422383785247803\n",
      "Concept supervision loss 1.82681405544281\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  4\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 38.28125   ACC Y 69.3359375 F1 Y 43.24387196268513 F1 C 24.42894241569243\n",
      "\n",
      "Epoch 6/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 58.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0131 | Avg Acc: 0.9960\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 2.045747756958008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:27 ] epoch 5: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.74092066"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.9510802030563354\n",
      "Concept supervision loss 2.1841917037963867\n",
      "Concept supervision loss 2.111621379852295\n",
      "Concept supervision loss 2.129869222640991\n",
      "Concept supervision loss 1.9483141899108887\n",
      "Concept supervision loss 2.0028772354125977\n",
      "Concept supervision loss 1.9267501831054688\n",
      "Concept supervision loss 1.9681259393692017\n",
      "Concept supervision loss 1.9864253997802734\n",
      "Concept supervision loss 2.0053231716156006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:27 ] epoch 5: |██████████████████████████████████████████████████| loss: 0.52732664"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.119478940963745\n",
      "Concept supervision loss 2.306187391281128\n",
      "Concept supervision loss 1.9701929092407227\n",
      "Concept supervision loss 2.083740711212158\n",
      "Concept supervision loss 2.0373053550720215\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  5\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 45.3125   ACC Y 69.140625 F1 Y 43.06892473384853 F1 C 27.449349981339548\n",
      "\n",
      "Epoch 7/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 60.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0119 | Avg Acc: 0.9968\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 1.9922120571136475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:27 ] epoch 6: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.4613609"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.1209185123443604\n",
      "Concept supervision loss 1.9555058479309082\n",
      "Concept supervision loss 2.0033018589019775\n",
      "Concept supervision loss 1.9798011779785156\n",
      "Concept supervision loss 2.0395867824554443\n",
      "Concept supervision loss 2.006479501724243\n",
      "Concept supervision loss 2.1281070709228516\n",
      "Concept supervision loss 1.9748618602752686\n",
      "Concept supervision loss 2.0804357528686523\n",
      "Concept supervision loss 1.9352262020111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:27 ] epoch 6: |██████████████████████████████████████████████████| loss: 0.53560084"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.1283347606658936\n",
      "Concept supervision loss 2.1748931407928467\n",
      "Concept supervision loss 2.1058437824249268\n",
      "Concept supervision loss 2.135774850845337\n",
      "Concept supervision loss 1.8908339738845825\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  6\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 46.728515625   ACC Y 68.9453125 F1 Y 41.97147410457349 F1 C 27.059673255746368\n",
      "\n",
      "Epoch 8/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 55.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0106 | Avg Acc: 0.9960\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 1.828769564628601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:27 ] epoch 7: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.70212555"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.8137893676757812\n",
      "Concept supervision loss 1.9601502418518066\n",
      "Concept supervision loss 1.9654263257980347\n",
      "Concept supervision loss 2.008023262023926\n",
      "Concept supervision loss 1.8372503519058228\n",
      "Concept supervision loss 2.034381866455078\n",
      "Concept supervision loss 2.0031538009643555\n",
      "Concept supervision loss 2.135354518890381\n",
      "Concept supervision loss 1.9279747009277344\n",
      "Concept supervision loss 2.072425127029419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:28 ] epoch 7: |██████████████████████████████████████████████████| loss: 0.54622662"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.090492010116577\n",
      "Concept supervision loss 1.9117287397384644\n",
      "Concept supervision loss 2.1052393913269043\n",
      "Concept supervision loss 2.061692476272583\n",
      "Concept supervision loss 1.9368231296539307\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  7\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 54.00390625   ACC Y 70.5078125 F1 Y 47.54380455226449 F1 C 31.140064861043964\n",
      "\n",
      "Saving...\n",
      "Saved best model with F1 score: 47.54380455226449\n",
      "\n",
      "Epoch 9/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 66.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0016 | Avg Acc: 0.9996\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 1.9886866807937622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:28 ] epoch 8: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.50805593"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.908178448677063\n",
      "Concept supervision loss 2.051603078842163\n",
      "Concept supervision loss 2.108492374420166\n",
      "Concept supervision loss 1.94681715965271\n",
      "Concept supervision loss 1.889235496520996\n",
      "Concept supervision loss 1.9124746322631836\n",
      "Concept supervision loss 1.9838597774505615\n",
      "Concept supervision loss 2.117036819458008\n",
      "Concept supervision loss 1.9976801872253418\n",
      "Concept supervision loss 1.99128258228302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:28 ] epoch 8: |██████████████████████████████████████████████████| loss: 0.47364402"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 1.977266788482666\n",
      "Concept supervision loss 2.0585687160491943\n",
      "Concept supervision loss 2.207760810852051\n",
      "Concept supervision loss 2.098612070083618\n",
      "Concept supervision loss 1.9883277416229248\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  8\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 54.931640625   ACC Y 68.9453125 F1 Y 43.608593854253854 F1 C 30.338178844604464\n",
      "\n",
      "Epoch 10/10\n",
      "--- Training Protonet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 60.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Avg Loss: 0.0037 | Avg Acc: 0.9984\n",
      "--- Training with Unsupervised Data\n",
      "Concept supervision loss 2.09793758392334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:28 ] epoch 9: |███████┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈| loss: 0.56608486"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.169445514678955\n",
      "Concept supervision loss 1.9495428800582886\n",
      "Concept supervision loss 2.125377655029297\n",
      "Concept supervision loss 1.9852268695831299\n",
      "Concept supervision loss 2.0437614917755127\n",
      "Concept supervision loss 2.0374081134796143\n",
      "Concept supervision loss 1.9559051990509033\n",
      "Concept supervision loss 2.1409504413604736\n",
      "Concept supervision loss 2.0514023303985596\n",
      "Concept supervision loss 2.024290084838867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 07-22 | 13:28 ] epoch 9: |██████████████████████████████████████████████████| loss: 0.47109878"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept supervision loss 2.2098662853240967\n",
      "Concept supervision loss 2.102266311645508\n",
      "Concept supervision loss 2.055107593536377\n",
      "Concept supervision loss 1.96175217628479\n",
      "Concept supervision loss 2.115010976791382\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "End of epoch  9\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "  ACC C 51.904296875   ACC Y 70.8984375 F1 Y 49.30174010986737 F1 C 29.773476525950805\n",
      "\n",
      "Saving...\n",
      "Saved best model with F1 score: 49.30174010986737\n",
      "\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_distinct_labels = np.unique(proto_labels).size\n",
    "print(f\"*** Training model with seed {args.seed}\")\n",
    "print(\"Chosen device:\", model.device)\n",
    "print(\"Save path for this model: \", save_path)\n",
    "if not os.path.exists(save_path): \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "save_folder = os.path.join(save_path, f\"{model_parameter_name}_{args.seed}.pth\")\n",
    "print(\"Saving in folder: \", save_folder)\n",
    "\n",
    "best_f1 = train(model=model,\n",
    "    encoder=encoder,\n",
    "    episodic_dataloader=episodic_dataloader,\n",
    "    unsup_train_loader=mnmath_train_loader,\n",
    "    unsup_val_loader=mnmath_val_loader,\n",
    "    _loss=loss, \n",
    "    num_distinct_labels=num_distinct_labels,\n",
    "    args=args,\n",
    "    save_folder=save_folder,\n",
    ")\n",
    "save_model(model, args, args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b37868",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15445d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_concept_collapse(true_concepts, predicted_concepts, multilabel=False):\n",
    "    return 1 - compute_coverage(confusion_matrix(true_concepts, predicted_concepts))\n",
    "\n",
    "\n",
    "def evaluate_my_model(model: MnistDPL, \n",
    "        save_path: str, \n",
    "        my_loader: DataLoader,\n",
    "        seed: int,\n",
    "        support_images,\n",
    "        support_labels,\n",
    "    ):\n",
    "\n",
    "    # * Compute test set accuracies and F1 scores\n",
    "    _, cacc, yacc, f1_y, f1_c = evaluate_metrics(\n",
    "        model, my_loader, args, support_images=support_images, support_labels=support_labels\n",
    "    )\n",
    "    with open(save_path, \"a\") as f:\n",
    "        print(f\"Evaluation results for seed {seed}:\")\n",
    "        print(f\"    ACC(C): {round(cacc/100,2)}, \"\n",
    "              f\"ACC(Y): {round(yacc/100,2)}, \"\n",
    "              f\"F1(Y): {round(f1_y/100,2)}, \"\n",
    "              f\"F1(C): {round(f1_c/100,2)}\")\n",
    "        f.write(\n",
    "            f\"Evaluation results for seed {seed}:\\n\"\n",
    "            f\"    ACC(C): {round(cacc/100,2)}, \"\n",
    "            f\"ACC(Y): {round(yacc/100,2)}, \"\n",
    "            f\"F1(Y): {round(f1_y/100,2)}, \"\n",
    "            f\"F1(C): {round(f1_c/100,2)}\\n\"\n",
    "        )\n",
    "\n",
    "    # * Compute Concept Collapse\n",
    "    y_true, c_true, y_pred, c_pred, _, _, _, _ = evaluate_metrics(\n",
    "        model, my_loader, args, support_images=support_images, support_labels=support_labels, last=True\n",
    "    )\n",
    "    cls = compute_concept_collapse(c_true, c_pred)\n",
    "    with open(save_path, \"a\") as f:\n",
    "        print(f\"Cls(C): {round(cls,2):.4f}\")\n",
    "        f.write(f\"    Cls(C): {round(cls,2):.4f}\\n\")\n",
    "    return c_true, c_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "420629a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['promnistltn', 'promnmathcbm', 'sddoiann', 'kandnn', 'sddoiadpl', 'sddoialtn', 'presddoiadpl', 'boiann', 'mnistclip', 'prokanddpl', 'promnistdpl', 'xornn', 'mnistnn', 'mnistslrec', 'kandpreprocess', 'kandsl', 'kandsloneembedding', 'prokandltn', 'kandcbm', 'prokandsl', 'boiacbm', 'kanddpl', 'kandltn', 'xorcbm', 'sddoiaclip', 'xordpl', 'promnmathdpl', 'sddoiacbm', 'mnistltnrec', 'mnmathcbm', 'mnmathdpl', 'kandclip', 'minikanddpl', 'mnistdpl', 'mnistltn', 'boiadpl', 'boialtn', 'prokandsloneembedding', 'mnistpcbmdpl', 'mnistcbm', 'probddoiadpl', 'mnistpcbmsl', 'mnistpcbmltn', 'mnistsl', 'mnistdplrec', 'cvae', 'cext', 'mnmathnn', 'promnistsl']\n",
      "Evaluating model on test set with seed 1415...\n",
      "Evaluation results for seed 1415:\n",
      "    ACC(C): 0.52, ACC(Y): 0.7, F1(Y): 0.5, F1(C): 0.3\n",
      "Cls(C): 0.0000\n",
      "\n",
      "Evaluating model on OOD set with seed 1415...\n",
      "Evaluation results for seed 1415:\n",
      "    ACC(C): 0.54, ACC(Y): 0.94, F1(Y): 0.48, F1(C): 0.53\n",
      "Cls(C): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model object\n",
    "model = get_model(args, encoder, decoder, n_images, c_split)\n",
    "\n",
    "# Load the model state dictionary into the model object\n",
    "model_state_dict = torch.load(save_folder)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(args.device)\n",
    "\n",
    "# Create the metrics log path\n",
    "metrics_log_path = save_folder.replace(\".pth\", \"_test_metrics.log\")\n",
    "metrics_log_path = re.sub(r'_\\d+', '', metrics_log_path)\n",
    "\n",
    "# instantiate support images and labels for evaluation purposes\n",
    "this_support_images, this_support_labels = get_random_classes(\n",
    "    mnist_dataset.images, mnist_dataset.labels, args.n_support, num_distinct_labels)\n",
    "assert this_support_images.shape == (args.n_support * num_distinct_labels, 1, 28, 28), \\\n",
    "    f\"Support images shape is not ({args.n_support * num_distinct_labels}, 1, 28, 28), but {this_support_images.shape}\"\n",
    "assert this_support_labels.shape == (args.n_support * num_distinct_labels, 1), \\\n",
    "    f\"Support labels shape is not ({args.n_support * num_distinct_labels}, 1), but {this_support_labels.shape}\"\n",
    "\n",
    "# Evaluate the model over the **test** set\n",
    "print(f\"Evaluating model on test set with seed {args.seed}...\")\n",
    "c_true_test, c_pred_test = evaluate_my_model(\n",
    "    model=model, \n",
    "    save_path=metrics_log_path, \n",
    "    my_loader=mnmath_test_loader, \n",
    "    seed=args.seed,\n",
    "    support_images=this_support_images,\n",
    "    support_labels=this_support_labels,\n",
    ")\n",
    "print()\n",
    "\n",
    "# Evaluate the model over the **OOD** set\n",
    "print(f\"Evaluating model on OOD set with seed {args.seed}...\")\n",
    "metrics_log_path = save_folder.replace(\".pth\", \"_ood_metrics.log\")\n",
    "metrics_log_path = re.sub(r'_\\d+', '', metrics_log_path)\n",
    "c_true_ood, c_pred_ood = evaluate_my_model(\n",
    "    model=model, \n",
    "    save_path=metrics_log_path, \n",
    "    my_loader=mnmath_ood_loader, \n",
    "    seed=args.seed,\n",
    "    support_images=this_support_images,\n",
    "    support_labels=this_support_labels,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r4rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
