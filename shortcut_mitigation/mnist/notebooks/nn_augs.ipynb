{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# model's seeds\n",
    "s1 = 0\n",
    "s2 = None\n",
    "s3 = None\n",
    "s4 = None\n",
    "s5 = None\n",
    "s6 = None\n",
    "s7 = None\n",
    "s8 = None\n",
    "s9 = None\n",
    "s10 = None\n",
    "\n",
    "# additional paramters\n",
    "model_parameter_name = 'sl'\n",
    "uns_parameter_percentage = 1.0\n",
    "sup_loss_weight = 1.0\n",
    "GPU_ID = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_list = [int(s) for s in [s1, s2, s3, s4, s5, s6, s7, s8, s9, s10] if s is not None]\n",
    "\n",
    "assert len(seeds_list) > 0, \"seeds_list should have at least one entry\"\n",
    "assert all(isinstance(seed, int) for seed in seeds_list), \"Not all entries are integers\"\n",
    "assert model_parameter_name is not None, \"model_parameter_name should not be None\"\n",
    "assert uns_parameter_percentage is not None, \"uns_parameter_percentage should not be None\"\n",
    "assert sup_loss_weight is not None, \"sup_loss_weight should not be None\"\n",
    "assert GPU_ID is not None, \"GPU_ID should not be None\"\n",
    "\n",
    "print(\"Papermill seeds parameters are: \" + str(seeds_list))\n",
    "print(\"Papermill model name is: \" + model_parameter_name)\n",
    "print(\"Papermill uns_parameter_percentage is: \" + str(uns_parameter_percentage))\n",
    "print(\"Papermill sup_loss_weight is: \" + str(sup_loss_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID\n",
    "sys.path.append(os.path.abspath(\"..\"))       # for 'protonet_mnist_add_utils' folder\n",
    "sys.path.append(os.path.abspath(\"../..\"))    # for 'data' folder\n",
    "sys.path.append(os.path.abspath(\"../../..\")) # for 'models' and 'datasets' folders\n",
    "\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import datetime\n",
    "import importlib\n",
    "import setproctitle, socket, uuid\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "from numpy import float32, zeros\n",
    "from datasets import get_dataset\n",
    "from models import get_model\n",
    "from models.mnistdpl import MnistDPL\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from datasets.utils.base_dataset import BaseDataset\n",
    "from torchvision import datasets, transforms\n",
    "from cv2 import (\n",
    "    INTER_CUBIC, \n",
    "    getRotationMatrix2D, \n",
    "    imread, \n",
    "    warpAffine, \n",
    "    moments, \n",
    "    WARP_INVERSE_MAP\n",
    ")\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import fprint\n",
    "from utils.train import train\n",
    "from utils.test import test\n",
    "from utils.preprocess_resnet import preprocess\n",
    "from utils.conf import *\n",
    "from utils.args import *\n",
    "from utils.status import progress_bar\n",
    "from utils.checkpoint import save_model, create_load_ckpt\n",
    "from utils.dpl_loss import ADDMNIST_DPL\n",
    "from utils.metrics import (\n",
    "    evaluate_metrics,\n",
    "    evaluate_mix,\n",
    "    mean_entropy,\n",
    ")\n",
    "from protonet_mnist_add_modules.utility_modules.proto_utils import ( \n",
    "    init_dataloader,\n",
    "    get_random_classes\n",
    ")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from protonet_mnist_add_modules.arguments import args_sl, args_ltn, args_dpl\n",
    "from protonet_mnist_add_modules.utility_modules.plotting import plot_training_image\n",
    "from protonet_mnist_add_modules.data_modules.proto_data_creation import (\n",
    "    choose_initial_prototypes,\n",
    "    get_original_support_query_set,\n",
    "    get_augmented_support_query_set,\n",
    "    get_augmented_support_query_loader\n",
    ")\n",
    "from backbones.addmnist_protonet import PrototypicalLoss\n",
    "\n",
    "from protonet_mnist_add_modules.utility_modules.setup import my_gpu_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = model_parameter_name\n",
    "UNS_PERCENTAGE = uns_parameter_percentage\n",
    "CONCEPT_LOSS_WEIGHT = sup_loss_weight\n",
    "if CONCEPT_LOSS_WEIGHT > 1.0 and MODEL != 'sl':\n",
    "    raise Exception(\"Concept loss weight should be less than or equal to 1.0 for DPL and LTN\")\n",
    "elif MODEL != 'sl':\n",
    "    assert CONCEPT_LOSS_WEIGHT == 1.0, 'Loss weight greater than 1 is only for SL'\n",
    "\n",
    "print(\"Model: \", MODEL)\n",
    "print(\"Unsupervised Percentage: \", UNS_PERCENTAGE)\n",
    "print(\"Concept Loss Weight: \", CONCEPT_LOSS_WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == 'sl':       args = args_sl\n",
    "elif MODEL == 'ltn':    args = args_ltn\n",
    "else:                   args = args_dpl\n",
    "\n",
    "args.seeds = seeds_list\n",
    "print(\"Seeds: \" + str(args.seeds))\n",
    "\n",
    "# logging\n",
    "args.conf_jobnum = str(uuid.uuid4())\n",
    "args.conf_timestamp = str(datetime.datetime.now())\n",
    "args.conf_host = socket.gethostname()\n",
    "\n",
    "# set job name\n",
    "setproctitle.setproctitle(\n",
    "    \"{}_{}_{}\".format(\n",
    "        args.model,\n",
    "        args.buffer_size if \"buffer_size\" in args else 0,\n",
    "        args.dataset,\n",
    "    )\n",
    ")\n",
    "\n",
    "# saving\n",
    "save_folder = \"mnadd-even-odd\" \n",
    "save_model_name = MODEL\n",
    "save_paths = []\n",
    "for i in range(len(args.prototypical_loss_weight)):\n",
    "    save_path = os.path.join(\"..\", \"..\", \n",
    "        \"outputs\", \n",
    "        save_folder, \n",
    "        \"my_models\", \n",
    "        save_model_name,\n",
    "        f\"DEBUG-baseline-concept-supervised-{UNS_PERCENTAGE}-ARTICLE\"\n",
    "    )\n",
    "    save_paths.append(save_path)\n",
    "print(f\"Save paths: {str(save_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model not in ['mnistsl', 'mnistltn', 'mnistdpl'] or args.prototypes:\n",
    "    raise ValueError(\"This experiment is meant for baseline models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * for training data inspection\n",
    "def plot_training_image(images, labels, plot_index_start=0, plot_index_end=10):\n",
    "    for plotting_index in range(plot_index_start, plot_index_end + 1):\n",
    "        image = images[plotting_index].cpu().numpy().transpose(1, 2, 0)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"Label {labels[plotting_index]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * For prototypes computation at test phase \n",
    "def get_random_classes(images, labels, n_support):\n",
    "    unique_classes = torch.unique(labels)\n",
    "    assert len(unique_classes) == 10, \"There should be exactly 10 unique classes.\"\n",
    "\n",
    "    selected_images = []\n",
    "    selected_labels = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        class_indices = (labels == cls).nonzero(as_tuple=True)[0]\n",
    "        assert len(class_indices) >= n_support, f\"Not enough samples for class {cls}\"\n",
    "        random_indices = torch.randperm(len(class_indices))[:n_support]\n",
    "        selected_images.append(images[class_indices[random_indices]])\n",
    "        selected_labels.append(labels[class_indices[random_indices]])\n",
    "\n",
    "    selected_images = torch.cat(selected_images)\n",
    "    selected_labels = torch.cat(selected_labels)\n",
    "\n",
    "    return selected_images, selected_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data for training the ProtoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_protonet = Namespace(\n",
    "    dataset=args.prototypical_dataset,     \n",
    "    batch_size=args.prototypical_batch_size,\n",
    "    preprocess=0,\n",
    "    c_sup=1, # ^ supervision loaded to simulate direct annotation for prototypes\n",
    "    which_c=[-1],\n",
    "    model=args.model,        \n",
    "    task=args.task,    \n",
    ")\n",
    "\n",
    "addmnist_dataset = get_dataset(args_protonet)\n",
    "addmnist_train_loader, _ , _ = addmnist_dataset.get_data_loaders()\n",
    "print(addmnist_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create (or get) the initial annotated images-prototype seed and augment it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ( (not os.path.exists('data/prototypes/proto_loader_dataset.pth')) or args.debug ):\n",
    "    print(\"Creating proto_loader_dataset.pth\")\n",
    "    choose_initial_prototypes(addmnist_train_loader, debug=args.debug)\n",
    "\n",
    "tr_dataloader = init_dataloader()\n",
    "\n",
    "support_images_aug, support_labels_aug, query_images_aug, query_labels_aug, no_aug = get_augmented_support_query_set(\n",
    "    tr_dataloader, debug=args.debug)\n",
    "\n",
    "assert support_images_aug.numel() > 0, \"support_images_aug is an empty tensor\"\n",
    "assert support_labels_aug.numel() > 0, \"support_labels_aug is an empty tensor\"\n",
    "assert query_images_aug.numel() > 0, \"query_images_aug is an empty tensor\"\n",
    "assert query_labels_aug.numel() > 0, \"query_labels_aug is an empty tensor\"\n",
    "\n",
    "assert not torch.all(support_images_aug == 0), \"All elements in support_images_aug are zero\"\n",
    "assert not torch.all(support_labels_aug == 0), \"All elements in support_labels_aug are zero\"\n",
    "assert not torch.all(query_images_aug == 0), \"All elements in query_images_aug are zero\"\n",
    "assert not torch.all(query_labels_aug == 0), \"All elements in query_labels_aug are zero\"\n",
    "\n",
    "assert no_aug > 0, \"no_aug should be greater than 0\"\n",
    "\n",
    "support_loader, query_loader = get_augmented_support_query_loader(\n",
    "    support_images_aug, \n",
    "    support_labels_aug, \n",
    "    query_images_aug, \n",
    "    query_labels_aug,\n",
    "    query_batch_size=32,\n",
    "    debug=args.debug\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTAugDataset(Dataset):\n",
    "    def __init__(self, images, labels, hide_labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label.squeeze()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Example instantiation:\n",
    "mnist_dataset = MNISTAugDataset(support_images_aug, support_labels_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ten images from the MNISTAugDataset\n",
    "fig, axes = plt.subplots(5, 10, figsize=(15, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(mnist_dataset.images):\n",
    "        offset = random.randint(0, len(mnist_dataset.images) - 1)\n",
    "        image = mnist_dataset.images[offset].cpu().numpy().transpose(1, 2, 0)\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(f\"Label {mnist_dataset.labels[offset].item()}\")  \n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot_training_image(mnist_dataset.images, mnist_dataset.labels, plot_index_start=40, plot_index_end=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_train_loader = DataLoader(mnist_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Unsupervised Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(args)\n",
    "print(dataset)\n",
    "\n",
    "n_images, c_split = dataset.get_split()\n",
    "encoder, decoder = dataset.get_backbone()\n",
    "model = get_model(args, encoder, decoder, n_images, c_split)\n",
    "loss = model.get_loss(args)\n",
    "model.start_optim(args)\n",
    "\n",
    "print(\"Using Dataset: \", dataset)\n",
    "print(\"Using backbone: \", encoder)\n",
    "print(\"Using Model: \", model)\n",
    "print(\"Using Loss: \", loss)\n",
    "\n",
    "unsup_train_loader, unsup_val_loader, _ = dataset.get_data_loaders()\n",
    "dataset.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkig the Unsupervised Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(unsup_train_loader):\n",
    "    images, labels, concepts = data        \n",
    "    plot_training_image(images, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:MnistDPL,\n",
    "        sup_train_loader:DataLoader,\n",
    "        unsup_train_loader:DataLoader,\n",
    "        unsup_val_loader:DataLoader,\n",
    "        _loss: ADDMNIST_DPL, \n",
    "        args,\n",
    "        seed,\n",
    "        save_folder,\n",
    "        sup_loss_weight=1.0,\n",
    "        debug=False):\n",
    "    \n",
    "    # for full reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0   # for early stopping\n",
    "\n",
    "    # model configuration for shortmnist\n",
    "    if args.dataset == \"shortmnist\":    model = model.float()\n",
    "    model.to(model.device)\n",
    "\n",
    "    # get the data loaders\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(model.opt, args.exp_decay)\n",
    "    w_scheduler = None\n",
    "    if args.warmup_steps > 0:   w_scheduler = GradualWarmupScheduler(model.opt, 1.0, args.warmup_steps)\n",
    "\n",
    "    fprint(\"\\n--- Start of Training ---\\n\")\n",
    "\n",
    "    # default for warm-up\n",
    "    model.opt.zero_grad()\n",
    "    model.opt.step()\n",
    "\n",
    "    # & FOR EACH EPOCH\n",
    "    for epoch in range(args.proto_epochs):  # ^ ensure consistency with the number of epochs used for prototypical networks\n",
    "        model.train()\n",
    "\n",
    "        ###############################\n",
    "        # 1. Episodic phase: Teach the model to recognize digits\n",
    "        ###############################\n",
    "        print(\"Start of supervised episodic training.\")\n",
    "        for i, (images, labels) in enumerate(sup_train_loader):\n",
    "            sup_images = images.to(model.device)  # shape: (batch_size, C, 28, 28)\n",
    "            sup_labels = labels.to(model.device)  # shape: (batch_size,)\n",
    "            batch_size = sup_images.size(0)\n",
    "\n",
    "            assert sup_images.shape == torch.Size([batch_size, 1, 28, 28]), \\\n",
    "            f\"Expected shape [{batch_size}, 1, 28, 28], but got {sup_images.shape}\"\n",
    "            assert sup_labels.shape == torch.Size([batch_size]), \\\n",
    "            f\"Expected shape [{batch_size}], but got {sup_labels.shape}\"\n",
    "\n",
    "            # Ensure batch size is even to form pairs (if odd, drop the last sample)\n",
    "            if batch_size % 2 != 0:\n",
    "                sup_images = sup_images[:-1]\n",
    "                sup_labels = sup_labels[:-1]\n",
    "                batch_size -= 1\n",
    "                \n",
    "            # Merge pairs: merge 0 with 1, 2 with 3, and so on. This yields merged_images of shape (batch_size//2, C, 28, 56)\n",
    "            merged_images = torch.cat([sup_images[0::2], sup_images[1::2]], dim=3)\n",
    "\n",
    "            assert merged_images.shape == torch.Size([batch_size//2, 1, 28, 56]), \\\n",
    "            f\"Expected shape [{batch_size//2}, 1, 28, 56], but got {merged_images.shape}\"\n",
    "            \n",
    "            # Extract corresponding labels for each digit in the pair\n",
    "            labels_first = sup_labels[0::2]   # labels for the first digit in each pair\n",
    "            labels_second = sup_labels[1::2]  # labels for the second digit in each pair\n",
    "\n",
    "            # Plot the first merged image\n",
    "            if debug:\n",
    "                fig, axes = plt.subplots(1, min(5, merged_images.size(0)), figsize=(15, 3))\n",
    "                for idx in range(min(5, merged_images.size(0))):\n",
    "                    axes[idx].imshow(merged_images[idx].cpu().numpy().squeeze(), cmap='gray')\n",
    "                    axes[idx].set_title(f\"{labels_first[idx].item()}, {labels_second[idx].item()}\")\n",
    "                    axes[idx].axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "                \n",
    "            # Forward pass: the model expects an image with two digits\n",
    "            out_dict = model(merged_images)\n",
    "            nconcept_preds = out_dict[\"pCS\"]\n",
    "            \n",
    "            assert nconcept_preds.shape == torch.Size([batch_size//2, 2, 10]), \\\n",
    "                f\"Expected shape [{batch_size//2}, 2, 10], but got {nconcept_preds.shape}\"\n",
    "            \n",
    "            concept_loss_first = F.cross_entropy(nconcept_preds[:, 0], labels_first)\n",
    "            concept_loss_second = F.cross_entropy(nconcept_preds[:, 1], labels_second)\n",
    "            concept_loss = sup_loss_weight * (concept_loss_first + concept_loss_second)\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            model.opt.zero_grad()\n",
    "            concept_loss.backward()\n",
    "            model.opt.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Episodic phase, Epoch {epoch}, Batch {i}: Concept Loss = {concept_loss.item():.4f}\")\n",
    "        \n",
    "        ###############################\n",
    "        # 2. Original unsupervised training phase (sum prediction)\n",
    "        ###############################\n",
    "        # ys are the predictions of the model, y_true are the true labels, cs are the predictions of the concepts, cs_true are the true concepts\n",
    "        ys, y_true, cs, cs_true = None, None, None, None\n",
    "        \n",
    "        # & FOR EACH BATCH\n",
    "        print(\"Start of unsupervised training.\")\n",
    "        for i, data in enumerate(unsup_train_loader):\n",
    "            if random.random() > UNS_PERCENTAGE:\n",
    "                continue  # Skip this batch with probability (1 - percentage)\n",
    "\n",
    "            images, labels, concepts = data\n",
    "            images, labels, concepts = (\n",
    "                images.to(model.device),    # input IMAGES\n",
    "                labels.to(model.device),    # ground truth LABELS\n",
    "                concepts.to(model.device),  # ground truth CONCEPTS\n",
    "            )\n",
    "\n",
    "            # ^ baseline model\n",
    "            out_dict = model(images)\n",
    "\n",
    "            ''' Enrich the out_dict with the ground truth labels and concepts '''\n",
    "            out_dict.update({\"LABELS\": labels, \"CONCEPTS\": concepts})\n",
    "\n",
    "            ''' Extract the predicted concepts for the first image in the batch '''\n",
    "            model.opt.zero_grad()\n",
    "            loss, losses = _loss(out_dict, args)\n",
    "            loss.backward()\n",
    "            model.opt.step()\n",
    "            \n",
    "            if ys is None:  # first iteration\n",
    "                ys = out_dict[\"YS\"]\n",
    "                y_true = out_dict[\"LABELS\"]\n",
    "                cs = out_dict[\"pCS\"]\n",
    "                cs_true = out_dict[\"CONCEPTS\"]\n",
    "            else:           # all other iterations\n",
    "                ys = torch.concatenate((ys, out_dict[\"YS\"]), dim=0)\n",
    "                y_true = torch.concatenate((y_true, out_dict[\"LABELS\"]), dim=0)\n",
    "                cs = torch.concatenate((cs, out_dict[\"pCS\"]), dim=0)\n",
    "                cs_true = torch.concatenate((cs_true, out_dict[\"CONCEPTS\"]), dim=0)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress_bar(i, len(unsup_train_loader) - 9, epoch, loss.item())\n",
    "\n",
    "\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print(\"End of epoch \", epoch)\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print()\n",
    "        \n",
    "        if UNS_PERCENTAGE == 0.0:\n",
    "            print(\"Saving...\")\n",
    "            torch.save(model.state_dict(), save_folder)\n",
    "            print(f\"Saved best model with F1 score: {best_f1}\")\n",
    "            print()\n",
    "            continue\n",
    "        # this are the actual model predictions\n",
    "        y_pred = torch.argmax(ys, dim=-1)\n",
    "\n",
    "        \n",
    "        # enter the evaluation phase\n",
    "        model.eval()\n",
    "        # ^ baseline model\n",
    "        tloss, cacc, yacc, f1 = evaluate_metrics(model, unsup_val_loader, args)\n",
    "\n",
    "        # update the (warmup) scheduler at end of the epoch\n",
    "        if epoch < args.warmup_steps:\n",
    "            w_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            if hasattr(_loss, \"grade\"):\n",
    "                _loss.update_grade(epoch)\n",
    "\n",
    "        ### LOGGING ###\n",
    "        fprint(\"  ACC C\", cacc, \"  ACC Y\", yacc, \"F1 Y\", f1)\n",
    "        print()\n",
    "\n",
    "        if not args.tuning and f1 > best_f1:\n",
    "            print(\"Saving...\")\n",
    "            # Update best F1 score\n",
    "            best_f1 = f1\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), save_folder)\n",
    "            print(f\"Saved best model with F1 score: {best_f1}\")\n",
    "            print()\n",
    "        \n",
    "        elif f1 <= best_f1:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= args.patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    print(\"End of training\")\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = dict()\n",
    "save_path = save_paths[0]\n",
    "for seed in args.seeds:\n",
    "    print(f\"*** Training model with seed {seed}\")\n",
    "    print(\"Chosen device:\", model.device)\n",
    "    print(\"Save path for this model: \", save_path)\n",
    "    if not os.path.exists(save_path): os.makedirs(save_path, exist_ok=True)\n",
    "    save_folder = os.path.join(save_path, f\"{save_model_name}_{seed}.pth\")\n",
    "    print(\"Saving in folder: \", save_folder)\n",
    "\n",
    "    best_f1 = train(model=model,\n",
    "        sup_train_loader=sup_train_loader,\n",
    "        unsup_train_loader=unsup_train_loader,\n",
    "        unsup_val_loader=unsup_val_loader,\n",
    "        _loss=loss, \n",
    "        args=args,\n",
    "        seed=seed,\n",
    "        sup_loss_weight=CONCEPT_LOSS_WEIGHT,\n",
    "        save_folder=save_folder\n",
    "    )\n",
    "    f1_scores[seed] = best_f1\n",
    "    save_model(model, args, seed)  # save the model parameters\n",
    "\n",
    "best_weight_seed = max(f1_scores, key=f1_scores.get)\n",
    "print(f\"Best weight and seed combination: {best_weight_seed} with F1 score: {f1_scores[best_weight_seed]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r4rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
