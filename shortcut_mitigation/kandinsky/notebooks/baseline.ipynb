{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPERMILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's seeds\n",
    "s1 = 0\n",
    "s2 = None\n",
    "s3 = None\n",
    "s4 = None\n",
    "s5 = None\n",
    "s6 = None\n",
    "s7 = None\n",
    "s8 = None\n",
    "s9 = None\n",
    "s10 = None\n",
    "\n",
    "# additional paramters\n",
    "model_parameter_name = 'sl'\n",
    "GPU_ID = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papermill seeds parameters are: [0]\n",
      "Papermill model name is: sl\n",
      "Papermill GPU_ID is: 0\n"
     ]
    }
   ],
   "source": [
    "seeds_list = [int(s) for s in [s1, s2, s3, s4, s5, s6, s7, s8, s9, s10] if s is not None]\n",
    "\n",
    "assert len(seeds_list) > 0, \"seeds_list should have at least one entry\"\n",
    "assert all(isinstance(seed, int) for seed in seeds_list), \"Not all entries are integers\"\n",
    "assert model_parameter_name is not None, \"model_parameter_name should not be None\"\n",
    "assert GPU_ID is not None, \"GPU_ID should not be None\"\n",
    "\n",
    "print(\"Papermill seeds parameters are: \" + str(seeds_list))\n",
    "print(\"Papermill model name is: \" + model_parameter_name)\n",
    "print(\"Papermill GPU_ID is: \" + GPU_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation/kandinsky/notebooks', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python38.zip', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8/lib-dynload', '', '/users-1/eleonora/.local/lib/python3.8/site-packages', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8/site-packages', '/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation/kandinsky', '/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation', '/users-1/eleonora/reasoning-shortcuts/IXShort']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID\n",
    "sys.path.append(os.path.abspath(\"..\"))       # for 'protonet_mnist_add_utils' folder\n",
    "sys.path.append(os.path.abspath(\"../..\"))    # for 'data' folder\n",
    "sys.path.append(os.path.abspath(\"../../..\")) # for 'models' and 'datasets' folders\n",
    "\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import argparse\n",
    "import datetime\n",
    "import importlib\n",
    "import setproctitle, socket, uuid\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "from numpy import float32, zeros\n",
    "from datasets import get_dataset\n",
    "from models import get_model\n",
    "from models.mnistdpl import MnistDPL\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from datasets.utils.base_dataset import BaseDataset\n",
    "from torchvision import datasets, transforms\n",
    "from utils import fprint\n",
    "from utils.train import train\n",
    "from utils.test import test\n",
    "from utils.preprocess_resnet import preprocess\n",
    "from utils.conf import *\n",
    "from utils.args import *\n",
    "from utils.status import progress_bar\n",
    "from utils.checkpoint import save_model, create_load_ckpt\n",
    "from utils.dpl_loss import ADDMNIST_DPL\n",
    "from utils.metrics import (\n",
    "    evaluate_metrics,\n",
    "    evaluate_mix,\n",
    "    mean_entropy,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from protonet_kand_modules.arguments import args_dpl, args_sl, args_ltn\n",
    "from protonet_kand_modules.utility_modules.check_gpu import my_gpu_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save paths: ['../outputs/kand/baseline-DEBUG/sl']\n"
     ]
    }
   ],
   "source": [
    "if model_parameter_name == 'dpl':   args = args_dpl\n",
    "elif model_parameter_name == 'sl':  args = args_sl\n",
    "else:                               args = args_ltn\n",
    "\n",
    "# saving\n",
    "save_folder = \"kand\" \n",
    "save_model_name = model_parameter_name\n",
    "save_paths = []\n",
    "save_path = os.path.join(\"..\", \"outputs\", \n",
    "    save_folder, \n",
    "    \"baseline-DEBUG\", \n",
    "    save_model_name\n",
    ")\n",
    "save_paths.append(save_path)\n",
    "print(f\"Save paths: {str(save_paths)}\")\n",
    "\n",
    "if args.model in ['prokandsl', 'prokandltn', 'prokanddpl'] or args.prototypes:\n",
    "    raise ValueError(\"This experiment is NOT meant for pNet based models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  1.13.0+cu117\n",
      "CUDA version:  11.7\n",
      "Number of GPUs available: 1\n",
      "Device 0: NVIDIA GeForce GTX TITAN X\n",
      "  Memory Allocated: 0 bytes\n",
      "  Memory Cached: 0 bytes\n"
     ]
    }
   ],
   "source": [
    "my_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add uuid, timestamp and hostname for logging\n",
    "args.conf_jobnum = str(uuid.uuid4())\n",
    "args.conf_timestamp = str(datetime.datetime.now())\n",
    "args.conf_host = socket.gethostname()\n",
    "\n",
    "# set job name\n",
    "setproctitle.setproctitle(\n",
    "    \"{}_{}_{}\".format(\n",
    "        args.model,\n",
    "        args.buffer_size if \"buffer_size\" in args else 0,\n",
    "        args.dataset,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['mnmath', 'xor', 'clipboia', 'shortmnist', 'restrictedmnist', 'minikandinsky', 'presddoia', 'prekandinsky', 'sddoia', 'clipkandinsky', 'addmnist', 'clipshortmnist', 'boia_original', 'boia_original_embedded', 'clipsddoia', 'boia', 'kandinsky', 'halfmnist']\n",
      "kand says Namespace(and_op='Prod', backbone='conceptizer', batch_size=32, beta=0.99, boia_model='ce', boia_ood_knowledge=False, c_sup=0.0, c_sup_ltn=0, checkin=None, checkout=False, classes_per_it=3, concept_extractor_path='ultralytics/finetuned/kand_best_100.pt', conf_host='pssr', conf_jobnum='2bcb2bf6-5162-4a95-8f05-2b6bd2749bb0', conf_timestamp='2025-08-28 15:34:31.832556', count=30, dataset='kandinsky', debug=False, device=device(type='cuda'), embedding_dim=1024, entity='', entropy=False, exp_decay=0.9, extractor_training_epochs=20, gamma=0.001, imp_op='Prod', iterations=100, joint=False, lr=0.001, model='kandslsinglejoint', n_epochs=40, n_support=75, non_verbose=False, notes=None, num_distinct_labels=3, num_query=5, num_samples=10, num_support=5, or_op='Prod', p=2, patience=5, posthoc=False, preprocess=False, proj_name='', project='Reasoning-Shortcuts', proto_epochs=10, proto_lr=0.001, prototypes=False, prototypical_batch_size=32, prototypical_loss_weight=[1.0], retrain_extractor=False, seeds=[0, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768], splitted=False, task='patterns', tuning=False, use_ood=False, val_metric='accuracy', validate=False, w_c=1, w_h=1, w_rec=1, w_sl=10.0, wandb=None, warmup_steps=0, weight_decay=0.0001, which_c=[-1]) None\n",
      "Available models: ['promnistltn', 'promnmathcbm', 'sddoiann', 'kandnn', 'sddoiadpl', 'sddoialtn', 'kandslsingledisj', 'presddoiadpl', 'boiann', 'mnistclip', 'prokanddpl', 'promnistdpl', 'kandltnsinglejoint', 'xornn', 'mnistnn', 'mnistslrec', 'kandpreprocess', 'kandsl', 'kandsloneembedding', 'prokandltn', 'kandcbm', 'prokandsl', 'boiacbm', 'kanddpl', 'kandltn', 'xorcbm', 'sddoiaclip', 'kanddplsinglejoint', 'xordpl', 'promnmathdpl', 'sddoiacbm', 'mnistltnrec', 'mnmathcbm', 'mnmathdpl', 'kandclip', 'minikanddpl', 'mnistdpl', 'mnistltn', 'boiadpl', 'boialtn', 'kandltnsingledisj', 'prokandsloneembedding', 'mnistpcbmdpl', 'mnistcbm', 'probddoiadpl', 'mnistpcbmsl', 'mnistpcbmltn', 'kanddplsingledisj', 'mnistsl', 'kandslsinglejoint', 'mnistdplrec', 'cvae', 'cext', 'mnmathnn', 'promnistsl']\n",
      "Using Dataset:  <datasets.kandinsky.Kandinsky object at 0x7f4a20096190>\n",
      "Number of images:  3\n",
      "Using backbone:  SingleJointMLP(\n",
      "  (backbone): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=12288, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=128, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "Using Model:  KandSLSingleJoint(\n",
      "  (encoder): SingleJointMLP(\n",
      "    (backbone): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (1): Linear(in_features=12288, out_features=256, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=128, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Using Loss:  KANDINSKY_SL()\n",
      "Working with taks:  patterns\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(args)\n",
    "n_images, c_split = dataset.get_split()\n",
    "encoder, decoder = dataset.get_backbone()\n",
    "model = get_model(args, encoder, decoder, n_images, c_split)\n",
    "loss = model.get_loss(args)\n",
    "model.start_optim(args)\n",
    "\n",
    "print(\"Using Dataset: \", dataset)\n",
    "print(\"Number of images: \", n_images)\n",
    "print(\"Using backbone: \", encoder)\n",
    "print(\"Using Model: \", model)\n",
    "print(\"Using Loss: \", loss)\n",
    "print(\"Working with taks: \", args.task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: MnistDPL, dataset: BaseDataset, _loss: ADDMNIST_DPL, args, save_folder: str, patience: int = 5):\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0   # for early stopping\n",
    "\n",
    "    model.to(model.device)\n",
    "\n",
    "    train_loader, val_loader, test_loader = dataset.get_data_loaders()\n",
    "    dataset.print_stats()\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(model.opt, args.exp_decay)\n",
    "    w_scheduler = None\n",
    "    if args.warmup_steps > 0:   w_scheduler = GradualWarmupScheduler(model.opt, 1.0, args.warmup_steps)\n",
    "\n",
    "    fprint(\"\\n--- Start of Training ---\\n\")\n",
    "\n",
    "    # default for warm-up\n",
    "    model.opt.zero_grad()\n",
    "    model.opt.step()\n",
    "\n",
    "    # ^ Start of training\n",
    "    for epoch in range(args.n_epochs):\n",
    "        model.train()\n",
    "\n",
    "        ys, y_true, cs, cs_true = None, None, None, None\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, labels, concepts = data\n",
    "            images, labels, concepts = (\n",
    "                images.to(model.device),\n",
    "                labels.to(model.device),\n",
    "                concepts.to(model.device),\n",
    "            )\n",
    "\n",
    "            out_dict = model(images)\n",
    "            out_dict.update({\"LABELS\": labels, \"CONCEPTS\": concepts})\n",
    "            \n",
    "            model.opt.zero_grad()\n",
    "            loss, losses = _loss(out_dict, args)\n",
    "\n",
    "            loss.backward()\n",
    "            model.opt.step()\n",
    "\n",
    "            if ys is None:\n",
    "                ys = out_dict[\"YS\"]\n",
    "                y_true = out_dict[\"LABELS\"]\n",
    "                cs = out_dict[\"pCS\"]\n",
    "                cs_true = out_dict[\"CONCEPTS\"]\n",
    "            else:\n",
    "                ys = torch.concatenate((ys, out_dict[\"YS\"]), dim=0)\n",
    "                y_true = torch.concatenate((y_true, out_dict[\"LABELS\"]), dim=0)\n",
    "                cs = torch.concatenate((cs, out_dict[\"pCS\"]), dim=0)\n",
    "                cs_true = torch.concatenate((cs_true, out_dict[\"CONCEPTS\"]), dim=0)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress_bar(i, len(train_loader) - 9, epoch, loss.item())\n",
    "\n",
    "        y_pred = torch.argmax(ys, dim=-1)\n",
    "        #print(\"Argmax predictions have shape: \", y_pred.shape)\n",
    "\n",
    "        if \"patterns\" in args.task:\n",
    "            y_true = y_true[:, -1]  # it is the last one\n",
    "\n",
    "        model.eval()\n",
    "        tloss, cacc, yacc, f1 = evaluate_metrics(model, val_loader, args)\n",
    "\n",
    "        # update the (warmup) scheduler at end of the epoch\n",
    "        if epoch < args.warmup_steps:\n",
    "            w_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            if hasattr(_loss, \"grade\"):\n",
    "                _loss.update_grade(epoch)\n",
    "\n",
    "        ### LOGGING ###\n",
    "        fprint(\"  ACC C\", cacc, \"  ACC Y\", yacc, \"F1 Y\", f1)\n",
    "        print()\n",
    "\n",
    "        if not args.tuning and f1 > best_f1:\n",
    "            print(\"Saving...\")\n",
    "            # Update best F1 score\n",
    "            best_f1 = f1\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), save_folder)\n",
    "            print(f\"Saved best model with F1 score: {best_f1}\")\n",
    "            print()\n",
    "        \n",
    "        elif f1 <= best_f1:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    fprint(\"\\n--- End of Training ---\\n\")\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN ALL THINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training model with seed 0\n",
      "Chosen device: cuda\n",
      "Saving model in folder:  ../outputs/kand/baseline-DEBUG/sl/sl_0.pth\n",
      "Loaded datasets in 4.444101095199585 s.\n",
      "Len loaders: \n",
      " train: 4000 \n",
      " val: 1000\n",
      " len test: 1000\n",
      "## Statistics ##\n",
      "Train samples 4000\n",
      "Validation samples 1000\n",
      "Test samples 1000\n",
      "\n",
      "--- Start of Training ---\n",
      "\n",
      "Labels:  torch.Size([32, 4])\n",
      "Concepts:  torch.Size([32, 3, 6])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Debug stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m save_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving model in folder: \u001b[39m\u001b[38;5;124m\"\u001b[39m, save_folder)\n\u001b[0;32m----> 9\u001b[0m best_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m f1_scores[(seed)] \u001b[38;5;241m=\u001b[39m best_f1\n\u001b[1;32m     16\u001b[0m save_model(model, args, seed)  \u001b[38;5;66;03m# save the model parameters\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [9], line 36\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, _loss, args, save_folder, patience)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels: \u001b[39m\u001b[38;5;124m\"\u001b[39m, labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcepts: \u001b[39m\u001b[38;5;124m\"\u001b[39m, concepts\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebug stop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m out_dict \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     39\u001b[0m out_dict\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLABELS\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONCEPTS\u001b[39m\u001b[38;5;124m\"\u001b[39m: concepts})\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Debug stop"
     ]
    }
   ],
   "source": [
    "f1_scores = dict()\n",
    "for seed in args.seeds:\n",
    "    print(f\"*** Training model with seed {seed}\")\n",
    "    print(\"Chosen device:\", model.device)\n",
    "    if not os.path.exists(save_path): os.makedirs(save_path, exist_ok=True)\n",
    "    save_folder = os.path.join(save_path, f\"{save_model_name}_{seed}.pth\")\n",
    "    print(\"Saving model in folder: \", save_folder)\n",
    "\n",
    "    best_f1 = train(model=model,\n",
    "          dataset=dataset,\n",
    "        _loss=loss,\n",
    "        args=args,\n",
    "        save_folder=save_folder,\n",
    "    )\n",
    "    f1_scores[(seed)] = best_f1\n",
    "    save_model(model, args, seed)  # save the model parameters\n",
    "    \n",
    "    print(f\"*** Finished training model with seed {seed}\")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "best_weight_seed = max(f1_scores, key=f1_scores.get)\n",
    "print(f\"Best weight and seed combination: {best_weight_seed} with F1 score: {f1_scores[best_weight_seed]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r4rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
