{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db624e1e",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0a495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation/bddoia/notebooks', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python38.zip', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8/lib-dynload', '', '/users-1/eleonora/.local/lib/python3.8/site-packages', '/users-1/eleonora/anaconda3/envs/r4rr/lib/python3.8/site-packages', '/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation/bddoia', '/users-1/eleonora/reasoning-shortcuts/IXShort/shortcut_mitigation', '/users-1/eleonora/reasoning-shortcuts/IXShort']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "sys.path.append(os.path.abspath(\"..\"))       # for 'protonet_STOP_bddoia_modules' folder\n",
    "sys.path.append(os.path.abspath(\"../..\"))    # for 'data' folder\n",
    "sys.path.append(os.path.abspath(\"../../..\")) # for 'models' and 'datasets' folders\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a97cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import setproctitle, socket, uuid\n",
    "\n",
    "from models import get_model\n",
    "from models.mnistdpl import MnistDPL\n",
    "from datasets import get_dataset\n",
    "\n",
    "from argparse import Namespace\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "\n",
    "from utils import fprint\n",
    "from utils.status import progress_bar\n",
    "from utils.metrics import evaluate_metrics\n",
    "from utils.dpl_loss import ADDMNIST_DPL\n",
    "from utils.checkpoint import save_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from baseline_modules.arguments import args_dpl \n",
    "from backbones.bddoia_protonet import ProtoNetConv1D, PrototypicalLoss\n",
    "from protonet_STOP_bddoia_modules.proto_modules.proto_helpers import assert_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63b846",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce461ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "UNS_PERCENTAGE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0680d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0\n",
      "Save paths: ['../NEW-outputs/bddoia/baseline/dpl/baseline-disj']\n"
     ]
    }
   ],
   "source": [
    "args = args_dpl\n",
    "args.seed = SEED\n",
    "\n",
    "# logging\n",
    "args.conf_jobnum = str(uuid.uuid4())\n",
    "args.conf_timestamp = str(datetime.datetime.now())\n",
    "args.conf_host = socket.gethostname()\n",
    "\n",
    "# set job name\n",
    "setproctitle.setproctitle(\n",
    "    \"{}_{}_{}\".format(\n",
    "        args.model,\n",
    "        args.buffer_size if \"buffer_size\" in args else 0,\n",
    "        args.dataset,\n",
    "    )\n",
    ")\n",
    "\n",
    "# saving\n",
    "save_folder = \"bddoia\" \n",
    "save_model_name = 'dpl'\n",
    "save_paths = []\n",
    "save_path = os.path.join(\"..\",\n",
    "    \"NEW-outputs\", \n",
    "    save_folder, \n",
    "    \"baseline\", \n",
    "    save_model_name,\n",
    "    f\"baseline-disj\"\n",
    ")\n",
    "save_paths.append(save_path)\n",
    "\n",
    "print(\"Seed: \" + str(args.seed))\n",
    "print(f\"Save paths: {str(save_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1511d01",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c1be3",
   "metadata": {},
   "source": [
    "## Test Set Evaluation (alternative to full fledged notebook eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c24d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * helper function for 'plot_multilabel_confusion_matrix'\n",
    "def convert_to_categories(elements):\n",
    "    # Convert vector of 0s and 1s to a single binary representation along the first dimension\n",
    "    binary_rep = np.apply_along_axis(\n",
    "        lambda x: \"\".join(map(str, x)), axis=1, arr=elements\n",
    "    )\n",
    "    return np.array([int(x, 2) for x in binary_rep])\n",
    "\n",
    "\n",
    "# * BBDOIA custom confusion matrix for concepts\n",
    "def plot_multilabel_confusion_matrix(\n",
    "    y_true, y_pred, class_names, title, save_path=None\n",
    "):\n",
    "    y_true_categories = convert_to_categories(y_true.astype(int))\n",
    "    y_pred_categories = convert_to_categories(y_pred.astype(int))\n",
    "\n",
    "    to_rtn_cm = confusion_matrix(y_true_categories, y_pred_categories)\n",
    "\n",
    "    cm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    num_classes = len(class_names)\n",
    "    num_rows = (num_classes + 4) // 5  # Calculate the number of rows needed\n",
    "\n",
    "    plt.figure(figsize=(20, 4 * num_rows))  # Adjust the figure size\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        plt.subplot(num_rows, 5, i + 1)  # Set the subplot position\n",
    "        plt.imshow(cm[i], interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Class: {class_names[i]}\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(2)\n",
    "        plt.xticks(tick_marks, [\"0\", \"1\"])\n",
    "        plt.yticks(tick_marks, [\"0\", \"1\"])\n",
    "\n",
    "        fmt = \".0f\"\n",
    "        thresh = cm[i].max() / 2.0\n",
    "        for j in range(cm[i].shape[0]):\n",
    "            for k in range(cm[i].shape[1]):\n",
    "                plt.text(\n",
    "                    k,\n",
    "                    j,\n",
    "                    format(cm[i][j, k], fmt),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"white\" if cm[i][j, k] > thresh else \"black\",\n",
    "                )\n",
    "\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(f\"{save_path}_total.png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return to_rtn_cm\n",
    "\n",
    "\n",
    "# * Concept collapse (Soft)\n",
    "def compute_coverage(confusion_matrix):\n",
    "    \"\"\"Compute the coverage of a confusion matrix.\n",
    "\n",
    "    Essentially this metric is\n",
    "    \"\"\"\n",
    "\n",
    "    max_values = np.max(confusion_matrix, axis=0)\n",
    "    clipped_values = np.clip(max_values, 0, 1)\n",
    "\n",
    "    # Redefinition of soft coverage\n",
    "    coverage = np.sum(clipped_values) / len(clipped_values)\n",
    "\n",
    "    return coverage\n",
    "\n",
    "\n",
    "# * BDDOIA custom confusion matrix for actions\n",
    "def plot_actions_confusion_matrix(c_true, c_pred, title, save_path=None):\n",
    "\n",
    "    # Define scenarios and corresponding labels\n",
    "    my_scenarios = {\n",
    "        \"forward\": [slice(0, 3), slice(0, 3)],  \n",
    "        \"stop\": [slice(3, 9), slice(3, 9)],\n",
    "        \"left\": [slice(9, 11), slice(18,20)],\n",
    "        \"right\": [slice(12, 17), slice(12,17)],\n",
    "    }\n",
    "\n",
    "    to_rtn = {}\n",
    "\n",
    "    # Plot confusion matrix for each scenario\n",
    "    for scenario, indices in my_scenarios.items():\n",
    "\n",
    "        g_true = convert_to_categories(c_true[:, indices[0]].astype(int))\n",
    "        c_pred_scenario = convert_to_categories(c_pred[:, indices[1]].astype(int))\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(g_true, c_pred_scenario)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure()\n",
    "        plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "        plt.title(f\"{title} - {scenario}\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        n_classes = c_true[:, indices[0]].shape[1]\n",
    "\n",
    "        tick_marks = np.arange(2**n_classes)\n",
    "        plt.xticks(tick_marks, [\"\" for _ in range(len(tick_marks))])\n",
    "        plt.yticks(tick_marks, [\"\" for _ in range(len(tick_marks))])\n",
    "\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save or show plot\n",
    "        if save_path:\n",
    "            plt.savefig(f\"{save_path}_{scenario}.png\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        to_rtn.update({scenario: cm})\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    return to_rtn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3245d",
   "metadata": {},
   "source": [
    "# Other Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bce4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * method used to check if all encoder parameters are registered in the model's optimizer\n",
    "def check_optimizer_params(model):\n",
    "    \"\"\"Check that all encoder parameters are registered in the optimizer.\"\"\"\n",
    "    # Get all encoder parameters\n",
    "    encoder_params = []\n",
    "    for i in range(21):\n",
    "        encoder = model.encoder[i]\n",
    "        for name, param in encoder.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue  # skip frozen params\n",
    "            encoder_params.append((f\"encoder_{i}.{name}\", param))\n",
    "\n",
    "    # Get all parameters in the optimizer\n",
    "    opt_param_ids = set(id(p) for group in model.opt.param_groups for p in group['params'])\n",
    "\n",
    "    # Check each encoder param is in the optimizer\n",
    "    missing = [(name, p.shape) for name, p in encoder_params if id(p) not in opt_param_ids]\n",
    "\n",
    "    if missing:\n",
    "        print(\"⚠️ The following parameters are missing from the optimizer:\")\n",
    "        for name, shape in missing:\n",
    "            print(f\"  - {name}: {shape}\")\n",
    "        raise RuntimeError(\"Some encoder parameters are not registered in the optimizer.\")\n",
    "    else:\n",
    "        print(\"✅ All encoder parameters are correctly registered in the optimizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e79c9",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39a91b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['mnmath', 'xor', 'clipboia', 'shortmnist', 'restrictedmnist', 'minikandinsky', 'presddoia', 'prekandinsky', 'sddoia', 'clipkandinsky', 'addmnist', 'clipshortmnist', 'boia_original', 'boia_original_embedded', 'clipsddoia', 'boia', 'kandinsky', 'halfmnist']\n",
      "Available models: ['promnistltn', 'promnmathcbm', 'sddoiann', 'kandnn', 'sddoiadpl', 'sddoialtn', 'kandslsingledisj', 'presddoiadpl', 'boiann', 'mnistclip', 'prokanddpl', 'promnistdpl', 'kandltnsinglejoint', 'xornn', 'mnistnn', 'mnistslrec', 'kandpreprocess', 'kandsl', 'kandsloneembedding', 'prokandltn', 'kandcbm', 'prokandsl', 'boiacbm', 'kanddpl', 'kandltn', 'xorcbm', 'sddoiaclip', 'kanddplsinglejoint', 'xordpl', 'promnmathdpl', 'bddoiadpldisj', 'sddoiacbm', 'mnistltnrec', 'mnmathcbm', 'mnmathdpl', 'kandclip', 'minikanddpl', 'mnistdpl', 'mnistltn', 'boiadpl', 'boialtn', 'kandltnsingledisj', 'prokandsloneembedding', 'mnistpcbmdpl', 'mnistcbm', 'probddoiadpl', 'mnistpcbmsl', 'mnistpcbmltn', 'kanddplsingledisj', 'mnistsl', 'kandslsinglejoint', 'mnistdplrec', 'cvae', 'cext', 'mnmathnn', 'promnistsl']\n",
      "✅ All encoder parameters are correctly registered in the optimizer.\n",
      "<datasets.boia_original_embedded.FasterBDDOIADataset object at 0x7f2ec8616c70>\n",
      "Using Dataset:  <datasets.boia_original_embedded.FasterBDDOIADataset object at 0x7f2ec8616c70>\n",
      "Using backbone:  (BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "), BOIAConceptizer(\n",
      "  (enc1): Linear(in_features=2048, out_features=1, bias=True)\n",
      "))\n",
      "Using Model:  BddoiaDPLDisj()\n",
      "Using Loss:  SDDOIA_DPL()\n",
      "Dataset sizes - train: 16080, val: 2264, test: 4568\n",
      "Loaded datasets in 0.12s\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(args)\n",
    "n_images, c_split = dataset.get_split()\n",
    "\n",
    "encoder, decoder = dataset.get_backbone()\n",
    "assert isinstance(encoder, tuple) and len(encoder) == 21, \"encoder must be a tuple of 21 elements\"\n",
    "\n",
    "model = get_model(args, encoder, decoder, n_images, c_split)\n",
    "model.start_optim(args)\n",
    "check_optimizer_params(model)\n",
    "loss = model.get_loss(args)\n",
    "\n",
    "print(dataset)\n",
    "print(\"Using Dataset: \", dataset)\n",
    "print(\"Using backbone: \", encoder)\n",
    "print(\"Using Model: \", model)\n",
    "print(\"Using Loss: \", loss)\n",
    "\n",
    "unsup_train_loader, unsup_val_loader, unsup_test_loader = dataset.get_data_loaders(args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b138d",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32b4d4",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e14769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        model: MnistDPL, \n",
    "        _loss: ADDMNIST_DPL,\n",
    "        save_path: str,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        args: Namespace,\n",
    "        eval_concepts: list = None,\n",
    "        seed: int = 0,\n",
    "    ) -> float:\n",
    "\n",
    "    # for full reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "    # early stopping\n",
    "    best_cacc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    # scheduler & warmup (not used) for main model\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(model.opt, args.exp_decay)\n",
    "    w_scheduler = None\n",
    "    if args.warmup_steps > 0:\n",
    "        w_scheduler = GradualWarmupScheduler(model.opt, 1.0, args.warmup_steps)\n",
    "\n",
    "    fprint(\"\\n--- Start of Training ---\\n\")\n",
    "    model.to(model.device)\n",
    "    for b in range(len(model.encoder)):\n",
    "        model.encoder[b].train()\n",
    "        model.encoder[b].to(model.device)\n",
    "    \n",
    "    model.opt.zero_grad()\n",
    "    model.opt.step()\n",
    "\n",
    "    # & Training start\n",
    "    for epoch in range(args.n_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{args.n_epochs}\")\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        # * Unsupervised Training\n",
    "        print(\"Unsupervised training phase\")\n",
    "        ys, y_true, cs, cs_true, batch = None, None, None, None, 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            \n",
    "            # ------------------ original embneddings\n",
    "            images_embeddings = torch.stack(batch['embeddings']).to(model.device)\n",
    "            attr_labels = torch.stack(batch['attr_labels']).to(model.device)\n",
    "            class_labels = torch.stack(batch['class_labels'])[:,:-1].to(model.device)\n",
    "            # ------------------ my extracted features\n",
    "            images_embeddings_raw = torch.stack(batch['embeddings_raw']).to(model.device)\n",
    "            detected_rois = batch['rois']\n",
    "            detected_rois_feats = batch['roi_feats']\n",
    "            detection_labels = batch['detection_labels']\n",
    "            detection_scores = batch['detection_scores']\n",
    "            assert_inputs(images_embeddings, attr_labels, class_labels,\n",
    "                   detected_rois_feats, detected_rois, detection_labels,\n",
    "                   detection_scores, images_embeddings_raw)\n",
    "\n",
    "            out_dict = model(images_embeddings_raw)\n",
    "            out_dict.update({\"LABELS\": class_labels, \"CONCEPTS\": attr_labels})\n",
    "            \n",
    "            model.opt.zero_grad()\n",
    "            loss, losses = _loss(out_dict, args)\n",
    "\n",
    "            loss.backward()\n",
    "            model.opt.step()\n",
    "\n",
    "            if ys is None:\n",
    "                ys = out_dict[\"YS\"]\n",
    "                y_true = out_dict[\"LABELS\"]\n",
    "                cs = out_dict[\"pCS\"]\n",
    "                cs_true = out_dict[\"CONCEPTS\"]\n",
    "            else:\n",
    "                ys = torch.concatenate((ys, out_dict[\"YS\"]), dim=0)\n",
    "                y_true = torch.concatenate((y_true, out_dict[\"LABELS\"]), dim=0)\n",
    "                cs = torch.concatenate((cs, out_dict[\"pCS\"]), dim=0)\n",
    "                cs_true = torch.concatenate((cs_true, out_dict[\"CONCEPTS\"]), dim=0)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress_bar(i, len(train_loader) - 9, epoch, loss.item())\n",
    "            \n",
    "        # ^ Evaluation phase\n",
    "        y_pred = torch.argmax(ys, dim=-1)\n",
    "        #print(\"Argmax predictions have shape: \", y_pred.shape)\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        my_metrics = evaluate_metrics(\n",
    "                model=model, \n",
    "                loader=val_loader, \n",
    "                args=args,\n",
    "                eval_concepts=eval_concepts)\n",
    "        loss = my_metrics[0]\n",
    "        cacc = my_metrics[1]\n",
    "        yacc = my_metrics[2]\n",
    "        f1_y = my_metrics[3]\n",
    "       \n",
    "        # update at end of the epoch\n",
    "        if epoch < args.warmup_steps:   w_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            if hasattr(_loss, \"grade\"):\n",
    "                _loss.update_grade(epoch)\n",
    "\n",
    "        ### LOGGING ###\n",
    "        fprint(\"  ACC C\", cacc, \"  ACC Y\", yacc, \"F1 Y\", f1_y)\n",
    "        \n",
    "        if not args.tuning and cacc > best_cacc:\n",
    "            print(\"Saving...\")\n",
    "            # Update best F1 score\n",
    "            best_cacc = cacc\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Saved best model with CACC score: {best_cacc}\")\n",
    "\n",
    "        elif cacc <= best_cacc:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= args.patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "    fprint(\"\\n--- End of Training ---\\n\")\n",
    "    return best_cacc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e6feb",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df6353f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training model with seed 0\n",
      "Chosen device: cuda\n",
      "Saving model in folder:  ../NEW-outputs/bddoia/baseline/dpl/baseline-disj/dpl_0.pth\n",
      "\n",
      "--- Start of Training ---\n",
      "\n",
      "Epoch 1/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:31 ] epoch 0: |██████████████████████████████████████████████████| loss: 4.73461485"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 58.644857340388825   ACC Y 74.6004971590909 F1 Y 49.453690077617956\n",
      "Saving...\n",
      "Saved best model with CACC score: 58.644857340388825\n",
      "Epoch 2/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:31 ] epoch 1: |██████████████████████████████████████████████████| loss: 4.74198675"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 58.044170671039154   ACC Y 75.79407354797979 F1 Y 53.85242131449618\n",
      "Epoch 3/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:32 ] epoch 2: |██████████████████████████████████████████████████| loss: 4.68915987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 56.68440494272444   ACC Y 73.42369002525253 F1 Y 59.27764812560896\n",
      "Epoch 4/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:32 ] epoch 3: |██████████████████████████████████████████████████| loss: 4.66030788"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 60.39543516106076   ACC Y 75.89863478535354 F1 Y 58.19490986107035\n",
      "Saving...\n",
      "Saved best model with CACC score: 60.39543516106076\n",
      "Epoch 5/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:33 ] epoch 4: |██████████████████████████████████████████████████| loss: 4.67436743"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 67.630735039711   ACC Y 75.84734059343435 F1 Y 56.24353409812582\n",
      "Saving...\n",
      "Saved best model with CACC score: 67.630735039711\n",
      "Epoch 6/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:34 ] epoch 5: |██████████████████████████████████████████████████| loss: 4.68581676"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 67.7808599339591   ACC Y 76.43031881313132 F1 Y 60.242873132086984\n",
      "Saving...\n",
      "Saved best model with CACC score: 67.7808599339591\n",
      "Epoch 7/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:34 ] epoch 6: |██████████████████████████████████████████████████| loss: 4.72399959"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 66.82224074999492   ACC Y 76.12354008838383 F1 Y 59.285132949997546\n",
      "Epoch 8/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:35 ] epoch 7: |██████████████████████████████████████████████████| loss: 4.64077759"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 66.67211618688371   ACC Y 75.6747159090909 F1 Y 55.4908746055696\n",
      "Epoch 9/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:35 ] epoch 8: |██████████████████████████████████████████████████| loss: 4.67003012"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 67.292344239023   ACC Y 75.83057133838383 F1 Y 64.03060156270601\n",
      "Epoch 10/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:36 ] epoch 9: |██████████████████████████████████████████████████| loss: 4.65805292"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 67.64539149072435   ACC Y 76.42735953282828 F1 Y 62.885549925869945\n",
      "Epoch 11/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:37 ] epoch 10: |██████████████████████████████████████████████████| loss: 4.63746262"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 69.52411234378815   ACC Y 75.9716303661616 F1 Y 59.14573604488898\n",
      "Saving...\n",
      "Saved best model with CACC score: 69.52411234378815\n",
      "Epoch 12/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:37 ] epoch 11: |██████████████████████████████████████████████████| loss: 4.66167879"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 68.86855993005965   ACC Y 76.33562184343435 F1 Y 64.39736529599861\n",
      "Epoch 13/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:38 ] epoch 12: |██████████████████████████████████████████████████| loss: 4.66995478"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 65.54533541202545   ACC Y 76.11762152777777 F1 Y 63.9394179692482\n",
      "Epoch 14/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:38 ] epoch 13: |██████████████████████████████████████████████████| loss: 4.62524366"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 66.32339093420241   ACC Y 76.49739583333333 F1 Y 63.821181860758834\n",
      "Epoch 15/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:39 ] epoch 14: |██████████████████████████████████████████████████| loss: 4.63554621"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 63.63298296928406   ACC Y 75.96373895202021 F1 Y 61.951133101421455\n",
      "Epoch 16/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:40 ] epoch 15: |██████████████████████████████████████████████████| loss: 4.67619324"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 65.91453982724084   ACC Y 76.18173926767676 F1 Y 60.0940706833506\n",
      "Epoch 17/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:40 ] epoch 16: |██████████████████████████████████████████████████| loss: 4.70419645"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 65.78170160452525   ACC Y 75.89172979797979 F1 Y 55.524477213492766\n",
      "Epoch 18/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:41 ] epoch 17: |██████████████████████████████████████████████████| loss: 4.68155861"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 69.24227509233687   ACC Y 76.25473484848484 F1 Y 61.29554026277832\n",
      "Epoch 19/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:41 ] epoch 18: |██████████████████████████████████████████████████| loss: 4.60089827"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 65.84351824389563   ACC Y 75.91441761363636 F1 Y 58.94216893664639\n",
      "Epoch 20/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:42 ] epoch 19: |██████████████████████████████████████████████████| loss: 4.65861328"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 65.51715201801724   ACC Y 75.90849905303031 F1 Y 63.68523085584052\n",
      "Epoch 21/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:43 ] epoch 20: |██████████████████████████████████████████████████| loss: 4.62103367"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 66.50940279165904   ACC Y 76.50824652777777 F1 Y 58.92007348393876\n",
      "Epoch 22/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:43 ] epoch 21: |██████████████████████████████████████████████████| loss: 4.68025208"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 64.51005670759413   ACC Y 76.26755839646465 F1 Y 60.32646457004161\n",
      "Epoch 23/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:44 ] epoch 22: |██████████████████████████████████████████████████| loss: 4.70934772"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 64.23705187108781   ACC Y 76.49640940656565 F1 Y 61.56927581036402\n",
      "Epoch 24/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:44 ] epoch 23: |██████████████████████████████████████████████████| loss: 4.64116716"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 69.14814180798001   ACC Y 76.21527777777777 F1 Y 64.36664940377224\n",
      "Epoch 25/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:45 ] epoch 24: |██████████████████████████████████████████████████| loss: 4.60145092"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 67.43852264351315   ACC Y 76.19653566919192 F1 Y 62.628680392970494\n",
      "Epoch 26/40\n",
      "Unsupervised training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 09-04 | 16:46 ] epoch 25: |██████████████████████████████████████████████████| loss: 4.64889336"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACC C 65.4250853591495   ACC Y 76.21626420454545 F1 Y 60.77633240278068\n",
      "Early stopping triggered after 26 epochs.\n",
      "\n",
      "--- End of Training ---\n",
      "\n",
      "*** Finished training model with seed 0 and best CACC score 69.52411234378815\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "print(f\"*** Training model with seed {args.seed}\")\n",
    "print(\"Chosen device:\", model.device)\n",
    "if not os.path.exists(save_path): os.makedirs(save_path, exist_ok=True)\n",
    "save_folder = os.path.join(save_path, f\"{save_model_name}_{args.seed}.pth\")\n",
    "print(\"Saving model in folder: \", save_folder)\n",
    "\n",
    "eval_concepts = ['green_lights', 'follow_traffic', 'road_clear',\n",
    "        'traffic_lights', 'traffic_signs', 'cars', 'pedestrians', 'riders', 'others',\n",
    "        'no_lane_left', 'obstacle_left_lane', 'solid_left_line',\n",
    "                'on_right_turn_lane', 'traffic_light_right', 'front_car_right', \n",
    "        'no_lane_right', 'obstacle_right_lane', 'solid_right_line',\n",
    "                'on_left_turn_lane', 'traffic_light_left', 'front_car_left']\n",
    "\n",
    "best_cacc = train(\n",
    "        model=model,\n",
    "        train_loader=unsup_train_loader,\n",
    "        val_loader=unsup_val_loader,\n",
    "        save_path=save_folder,\n",
    "        _loss=loss,\n",
    "        args=args,\n",
    "        eval_concepts=eval_concepts,\n",
    "        seed=args.seed,\n",
    ")\n",
    "save_model(model, args, args.seed)  # save the model parameters\n",
    "print(f\"*** Finished training model with seed {args.seed} and best CACC score {best_cacc}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb08277",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a2e9e",
   "metadata": {},
   "source": [
    "## Evaluation Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892851c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_my_model(model: MnistDPL, \n",
    "        save_path: str, \n",
    "        test_loader: DataLoader,\n",
    "        eval_concepts,\n",
    "    ):\n",
    "    \n",
    "    my_metrics = evaluate_metrics(model, test_loader, args, \n",
    "                    eval_concepts=eval_concepts,)\n",
    "    \n",
    "    loss = my_metrics[0]\n",
    "    cacc = my_metrics[1]\n",
    "    yacc = my_metrics[2]\n",
    "    f1_y = my_metrics[3]\n",
    "    f1_micro = my_metrics[4]\n",
    "    f1_weight = my_metrics[5]\n",
    "    f1_bin = my_metrics[6]\n",
    "\n",
    "    metrics_log_path = save_path.replace(\".pth\", \"_metrics.log\")\n",
    "    \n",
    "    all_concepts = [ 'Green Traffic Light', 'Follow Traffic', 'Road Is Clear',\n",
    "        'Red Traffic Light', 'Traffic Sign', 'Obstacle Car', 'Obstacle Pedestrian', 'Obstacle Rider', 'Obstacle Others',\n",
    "        'No Lane On The Left',  'Obstacle On The Left Lane',  'Solid Left Line',\n",
    "                'On The Right Turn Lane', 'Traffic Light Allows Right', 'Front Car Turning Right', \n",
    "        'No Lane On The Right', 'Obstacle On The Right Lane', 'Solid Right Line',\n",
    "                'On The Left Turn Lane',  'Traffic Light Allows Left',  'Front Car Turning Left' \n",
    "    ]\n",
    "    aggregated_metrics = [\n",
    "            'F1 - Binary', 'F1 - Macro', 'F1 - Micro', 'F1 - Weighted',\n",
    "            'Precision - Binary', 'Precision - Macro', 'Precision - Micro', 'Precision - Weighted',\n",
    "            'Recall - Binary', 'Recall - Macro', 'Recall - Micro', 'Recall - Weighted',\n",
    "            'Balanced Accuracy'\n",
    "    ]\n",
    "\n",
    "    sums = [0.0] * len(aggregated_metrics)\n",
    "    num_concepts = len(all_concepts)\n",
    "    with open(metrics_log_path, \"a\") as log_file:\n",
    "        log_file.write(f\"ACC C: {cacc}, ACC Y: {yacc}\\n\\n\")\n",
    "        log_file.write(f\"F1 Y - Macro: {f1_y}, F1 Y - Micro: {f1_micro}, F1 Y - Weighted: {f1_weight}, F1 Y - Binary: {f1_bin} \\n\\n\")\n",
    "\n",
    "        def write_metrics(class_name, offset):\n",
    "            print(f\"Metrics for {class_name}:\")\n",
    "            log_file.write(f\"{class_name.upper()}\\n\")\n",
    "            for idx, metric_name in enumerate(aggregated_metrics):\n",
    "                value = my_metrics[offset + idx]\n",
    "                sums[idx] += value\n",
    "                log_file.write(f\"  {metric_name:<18} {value:.4f}\\n\")\n",
    "            log_file.write(\"\\n\")\n",
    "\n",
    "        i = 7\n",
    "        for concept in all_concepts:\n",
    "            write_metrics(concept, i)\n",
    "            i += len(aggregated_metrics)\n",
    "\n",
    "        log_file.write(\"MEAN ACROSS ALL CONCEPTS\\n\")\n",
    "        for idx, metric_name in enumerate(aggregated_metrics):\n",
    "            mean_value = sums[idx] / num_concepts\n",
    "            log_file.write(f\"  {metric_name:<18} {mean_value:.4f}\\n\")\n",
    "        log_file.write(\"\\n\")\n",
    "\n",
    "\n",
    "    assert len(my_metrics) == 7 + len(all_concepts) * len(aggregated_metrics), \\\n",
    "        f\"Expected {7 + len(all_concepts) * len(aggregated_metrics)} metrics, but got {len(my_metrics)}\"\n",
    "    y_true, c_true, y_pred, c_pred, p_cs, p_ys, p_cs_all, p_ys_all = (\n",
    "        evaluate_metrics(model, test_loader, args, \n",
    "                    eval_concepts=eval_concepts,\n",
    "                    last=True\n",
    "            )\n",
    "    )\n",
    "    y_labels = [\"stop\", \"forward\", \"left\", \"right\"]\n",
    "    concept_labels = [\n",
    "        \"green_light\",      \n",
    "        \"follow\",           \n",
    "        \"road_clear\",       \n",
    "        \"red_light\",        \n",
    "        \"traffic_sign\",     \n",
    "        \"car\",              \n",
    "        \"person\",           \n",
    "        \"rider\",            \n",
    "        \"other_obstacle\",   \n",
    "        \"left_lane\",\n",
    "        \"left_green_light\",\n",
    "        \"left_follow\",\n",
    "        \"no_left_lane\",\n",
    "        \"left_obstacle\",\n",
    "        \"letf_solid_line\",\n",
    "        \"right_lane\",\n",
    "        \"right_green_light\",\n",
    "        \"right_follow\",\n",
    "        \"no_right_lane\",\n",
    "        \"right_obstacle\",\n",
    "        \"right_solid_line\",\n",
    "    ]\n",
    "\n",
    "    plot_multilabel_confusion_matrix(y_true, y_pred, y_labels, \"Labels\", save_path=save_path)\n",
    "    cfs = plot_actions_confusion_matrix(c_true, c_pred, \"Concepts\", save_path=save_path)\n",
    "    cf = plot_multilabel_confusion_matrix(c_true, c_pred, concept_labels, \"Concepts\", save_path=save_path)\n",
    "    print(\"Concept collapse\", 1 - compute_coverage(cf))\n",
    "\n",
    "    with open(metrics_log_path, \"a\") as log_file:\n",
    "        for key, value in cfs.items():\n",
    "            log_file.write(f\"Concept collapse: {key}, {1 - compute_coverage(value):.4f}\\n\")\n",
    "            log_file.write(\"\\n\")\n",
    "\n",
    "    fprint(\"\\n--- End of Evaluation ---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87947313",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2806065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['promnistltn', 'promnmathcbm', 'sddoiann', 'kandnn', 'sddoiadpl', 'sddoialtn', 'kandslsingledisj', 'presddoiadpl', 'boiann', 'mnistclip', 'prokanddpl', 'promnistdpl', 'kandltnsinglejoint', 'xornn', 'mnistnn', 'mnistslrec', 'kandpreprocess', 'kandsl', 'kandsloneembedding', 'prokandltn', 'kandcbm', 'prokandsl', 'boiacbm', 'kanddpl', 'kandltn', 'xorcbm', 'sddoiaclip', 'kanddplsinglejoint', 'xordpl', 'promnmathdpl', 'bddoiadpldisj', 'sddoiacbm', 'mnistltnrec', 'mnmathcbm', 'mnmathdpl', 'kandclip', 'minikanddpl', 'mnistdpl', 'mnistltn', 'boiadpl', 'boialtn', 'kandltnsingledisj', 'prokandsloneembedding', 'mnistpcbmdpl', 'mnistcbm', 'probddoiadpl', 'mnistpcbmsl', 'mnistpcbmltn', 'kanddplsingledisj', 'mnistsl', 'kandslsinglejoint', 'mnistdplrec', 'cvae', 'cext', 'mnmathnn', 'promnistsl']\n",
      "Metrics for Green Traffic Light:\n",
      "Metrics for Follow Traffic:\n",
      "Metrics for Road Is Clear:\n",
      "Metrics for Red Traffic Light:\n",
      "Metrics for Traffic Sign:\n",
      "Metrics for Obstacle Car:\n",
      "Metrics for Obstacle Pedestrian:\n",
      "Metrics for Obstacle Rider:\n",
      "Metrics for Obstacle Others:\n",
      "Metrics for No Lane On The Left:\n",
      "Metrics for Obstacle On The Left Lane:\n",
      "Metrics for Solid Left Line:\n",
      "Metrics for On The Right Turn Lane:\n",
      "Metrics for Traffic Light Allows Right:\n",
      "Metrics for Front Car Turning Right:\n",
      "Metrics for No Lane On The Right:\n",
      "Metrics for Obstacle On The Right Lane:\n",
      "Metrics for Solid Right Line:\n",
      "Metrics for On The Left Turn Lane:\n",
      "Metrics for Traffic Light Allows Left:\n",
      "Metrics for Front Car Turning Left:\n",
      "Concept collapse 0.9633333333333334\n",
      "\n",
      "--- End of Evaluation ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model object\n",
    "model = get_model(args, encoder, decoder, n_images, c_split)\n",
    "\n",
    "# Load the model state dictionary into the model object\n",
    "model_state_dict = torch.load(save_folder)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "evaluate_my_model(model, save_folder, unsup_test_loader, eval_concepts=eval_concepts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r4rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
